{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13303078,"sourceType":"datasetVersion","datasetId":8432230}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# üåê Spatio-Temporal GNN Phase 4 - Multi-Scenario Climate Prediction\n\n**Complete STGNN notebook with multi-scenario training across 18 CMIP6 institutions**\n\n---\n\n## üìã Features\n- ‚úÖ **Spatio-Temporal Graph Neural Network** (unified spatial-temporal modeling)\n- ‚úÖ **Temporal Graph Convolutions** for time-aware processing\n- ‚úÖ **Multi-Scenario Training** (historical + SSP126/245/370/585)\n- ‚úÖ **Stratified Splitting** (all scenarios in train/val/test)\n- ‚úÖ **8-neighbor Grid Connectivity**\n- ‚úÖ **Scenario Embeddings** as 8th input channel\n- ‚úÖ Same dataset as ConvLSTM (7 vars + scenario ‚Üí precipitation)\n- ‚úÖ Memory-efficient for 6GB GPU\n- ‚úÖ Multi-institution support\n\n## üéØ STGNN Architecture\n- **Spatial**: Graph Convolution (8-neighbor)\n- **Temporal**: Temporal Convolution (causal)\n- **Combined**: Spatio-Temporal Blocks\n- **Input**: 12 timesteps √ó 8 channels √ó 9√ó19 spatial\n- **Output**: 3 timesteps √ó 1 variable √ó 9√ó19 spatial\n\n## üî¨ Why STGNN?\n- **Unified Processing**: Spatial + temporal in one operation\n- **Better Efficiency**: No separate GRU overhead\n- **Parallel Processing**: Temporal convolutions are parallelizable\n- **Climate-Appropriate**: Captures spatio-temporal patterns naturally\n\n---","metadata":{}},{"cell_type":"markdown","source":"## üì¶ Section 1: Install & Import Dependencies","metadata":{}},{"cell_type":"code","source":"!pip install torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv \\\n  -f https://data.pyg.org/whl/torch-2.6.0+cu124.html\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T11:31:58.435092Z","iopub.execute_input":"2025-10-09T11:31:58.435255Z","iopub.status.idle":"2025-10-09T11:32:07.782706Z","shell.execute_reply.started":"2025-10-09T11:31:58.435239Z","shell.execute_reply":"2025-10-09T11:32:07.781873Z"}},"outputs":[{"name":"stdout","text":"Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\nCollecting torch-geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting torch-scatter\n  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_scatter-2.1.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torch-sparse\n  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_sparse-0.6.18%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (5.0 MB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hCollecting torch-cluster\n  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_cluster-1.6.3%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting torch-spline-conv\n  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_spline_conv-1.2.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (1.0 MB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.12.15)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.9.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (7.1.0)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.0.9)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.5)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.15.3)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.6.4)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.8.3)\nRequirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch-geometric) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch-geometric) (2024.2.0)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-geometric, torch-cluster\nSuccessfully installed torch-cluster-1.6.3+pt26cu124 torch-geometric-2.6.1 torch-scatter-2.1.2+pt26cu124 torch-sparse-0.6.18+pt26cu124 torch-spline-conv-1.2.2+pt26cu124\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from torch_geometric.nn import GCNConv\nprint(\"‚úÖ PyTorch Geometric is working!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T11:32:07.783670Z","iopub.execute_input":"2025-10-09T11:32:07.783868Z","iopub.status.idle":"2025-10-09T11:32:20.007041Z","shell.execute_reply.started":"2025-10-09T11:32:07.783848Z","shell.execute_reply":"2025-10-09T11:32:20.006327Z"}},"outputs":[{"name":"stdout","text":"‚úÖ PyTorch Geometric is working!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ============================================================================\n# üì¶ SECTION 1: INSTALL & IMPORT DEPENDENCIES\n# ============================================================================\n\nimport os\nimport sys\nimport glob\nimport time\nimport json\nimport warnings\nimport gc\nfrom datetime import datetime\nfrom typing import Dict, List, Tuple, Optional\n\nimport numpy as np\nimport pandas as pd\nimport xarray as xr\nfrom scipy.ndimage import zoom\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch_geometric.nn import GCNConv\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\n\nwarnings.filterwarnings('ignore')\n\n# GPU setup\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"üöÄ Using device: {device}\")\nif torch.cuda.is_available():\n    print(f\"üìä GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\nelse:\n    print(\"‚ö†Ô∏è WARNING: No GPU detected - training will be VERY slow!\")\n\nsys.stdout.flush()\nprint(\"‚úÖ All imports successful!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T11:32:20.008948Z","iopub.execute_input":"2025-10-09T11:32:20.009362Z","iopub.status.idle":"2025-10-09T11:32:21.402669Z","shell.execute_reply.started":"2025-10-09T11:32:20.009344Z","shell.execute_reply":"2025-10-09T11:32:21.401904Z"}},"outputs":[{"name":"stdout","text":"üöÄ Using device: cuda\nüìä GPU: Tesla P100-PCIE-16GB\nüíæ GPU Memory: 15.9 GB\n‚úÖ All imports successful!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## ‚öôÔ∏è Section 2: Configuration","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# ‚öôÔ∏è SECTION 2: CONFIGURATION\n# ============================================================================\n\n# Paths\nINPUT_DATA_DIR = \"/kaggle/input/climate-dataset/Datasets/inputs/input4mips\"\nOUTPUT_DATA_DIR = \"/kaggle/input/climate-dataset/Datasets/outputs/CMIP6\"\nOUTPUT_DIR = \"stgnn_phase4_multiscenario_results\"\n\n# Training settings\nSMOKE_TEST = True              # True = 2 institutions, 2 epochs for testing\nRESUME_IF_MODEL_EXISTS = True  # Skip already trained models\nSKIP_TRAINING = False          # Set True to only load results\n\n# Memory settings\nTARGET_SPATIAL_H = 9\nTARGET_SPATIAL_W = 19\nBATCH_SIZE = 1\nEPOCHS = 2 if SMOKE_TEST else 15\n\n# Model settings (STGNN)\nHIDDEN_DIM = 64\nSTGNN_BLOCKS = 3              # Number of spatio-temporal blocks\nTEMPORAL_KERNEL_SIZE = 3       # Temporal convolution kernel\nSPATIAL_KERNEL_SIZE = 2        # Graph conv layers per block\nDROPOUT = 0.2\n\n# All 18 institutions\nALL_INSTITUTIONS = [\n    \"AWI-CM-1-1-MR\", \"BCC-CSM2-MR\", \"CAS-ESM2-0\", \"CESM2\",\n    \"CESM2-WACCM\", \"CMCC-CM2-SR5\", \"CMCC-ESM2\", \"CNRM-CM6-1-HR\",\n    \"EC-Earth3\", \"EC-Earth3-Veg\", \"EC-Earth3-Veg-LR\", \"FGOALS-f3-L\",\n    \"GFDL-ESM4\", \"INM-CM4-8\", \"INM-CM5-0\", \"MPI-ESM1-2-HR\",\n    \"MRI-ESM2-0\", \"TaiESM1\"\n]\n\n# Scenarios with numeric IDs\nSCENARIOS = {\n    'historical': 0,\n    'ssp126': 1,\n    'ssp245': 2,\n    'ssp370': 3,\n    'ssp585': 4\n}\n\n# Input variables (7 climate forcing variables)\nINPUT_VARIABLES = [\n    'BC_anthro_fires', 'BC_no_fires',\n    'CH4_anthro_fires', 'CH4_no_fires',\n    'CO2_sum',\n    'SO2_anthro_fires', 'SO2_no_fires'\n]\n\n# Total input channels: 7 variables + 1 scenario channel = 8\nNUM_INPUT_CHANNELS = 8\n\nOUTPUT_VARIABLE = 'pr'\n\n# Create directories\nos.makedirs(OUTPUT_DIR, exist_ok=True)\nos.makedirs(os.path.join(OUTPUT_DIR, \"checkpoints\"), exist_ok=True)\nos.makedirs(os.path.join(OUTPUT_DIR, \"logs\"), exist_ok=True)\nos.makedirs(os.path.join(OUTPUT_DIR, \"plots\"), exist_ok=True)\n\nprint(\"‚úÖ Configuration loaded\")\nprint(f\"   üìÅ Input: {INPUT_DATA_DIR}\")\nprint(f\"   üìÅ Output: {OUTPUT_DATA_DIR}\")\nprint(f\"   üíæ Results: {OUTPUT_DIR}\")\nprint(f\"   üó∫Ô∏è  Spatial: {TARGET_SPATIAL_H}√ó{TARGET_SPATIAL_W}\")\nprint(f\"   üè¢ Institutions: {len(ALL_INSTITUTIONS)}\")\nprint(f\"   üåç Scenarios: {list(SCENARIOS.keys())}\")\nprint(f\"   üìä Input channels: {NUM_INPUT_CHANNELS} (7 vars + scenario)\")\nprint(f\"   üîß STGNN blocks: {STGNN_BLOCKS}\")\nprint(f\"   ‚öôÔ∏è  Smoke test: {SMOKE_TEST}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T11:32:21.403972Z","iopub.execute_input":"2025-10-09T11:32:21.404462Z","iopub.status.idle":"2025-10-09T11:32:21.413057Z","shell.execute_reply.started":"2025-10-09T11:32:21.404433Z","shell.execute_reply":"2025-10-09T11:32:21.412370Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Configuration loaded\n   üìÅ Input: /kaggle/input/climate-dataset/Datasets/inputs/input4mips\n   üìÅ Output: /kaggle/input/climate-dataset/Datasets/outputs/CMIP6\n   üíæ Results: stgnn_phase4_multiscenario_results\n   üó∫Ô∏è  Spatial: 9√ó19\n   üè¢ Institutions: 18\n   üåç Scenarios: ['historical', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n   üìä Input channels: 8 (7 vars + scenario)\n   üîß STGNN blocks: 3\n   ‚öôÔ∏è  Smoke test: True\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## üó∫Ô∏è Section 3: Graph Construction Utilities","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# üó∫Ô∏è SECTION 3: GRAPH CONSTRUCTION\n# ============================================================================\n\ndef build_grid_graph_8neighbor(height: int, width: int) -> torch.Tensor:\n    \"\"\"Build 8-neighbor connectivity graph for grid.\"\"\"\n    edges = []\n    \n    def pos_to_idx(i, j):\n        return i * width + j\n    \n    # 8 directions: N, S, E, W, NE, NW, SE, SW\n    directions = [\n        (-1, 0), (1, 0), (0, -1), (0, 1),\n        (-1, -1), (-1, 1), (1, -1), (1, 1)\n    ]\n    \n    for i in range(height):\n        for j in range(width):\n            src_idx = pos_to_idx(i, j)\n            for di, dj in directions:\n                ni, nj = i + di, j + dj\n                if 0 <= ni < height and 0 <= nj < width:\n                    dst_idx = pos_to_idx(ni, nj)\n                    edges.append([src_idx, dst_idx])\n    \n    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n    print(f\"üìä Graph: {height}√ó{width} = {height*width} nodes, {edge_index.shape[1]} edges\")\n    print(f\"   Avg degree: {edge_index.shape[1] / (height*width):.2f}\")\n    return edge_index\n\n\ndef add_self_loops(edge_index: torch.Tensor, num_nodes: int) -> torch.Tensor:\n    \"\"\"Add self-loops to graph.\"\"\"\n    self_loops = torch.stack([torch.arange(num_nodes), torch.arange(num_nodes)], dim=0)\n    return torch.cat([edge_index, self_loops], dim=1)\n\n\ndef get_positional_encoding(height: int, width: int, embed_dim: int) -> torch.Tensor:\n    \"\"\"Generate 2D positional encoding.\"\"\"\n    y_coords = torch.linspace(0, 1, height)\n    x_coords = torch.linspace(0, 1, width)\n    yy, xx = torch.meshgrid(y_coords, x_coords, indexing='ij')\n    coords = torch.stack([yy.flatten(), xx.flatten()], dim=1)\n    \n    pos_encoding = torch.zeros(height * width, embed_dim)\n    for i in range(embed_dim // 2):\n        freq = 1.0 / (10000 ** (2 * i / embed_dim))\n        pos_encoding[:, 2*i] = torch.sin(coords[:, 0] * freq)\n        pos_encoding[:, 2*i + 1] = torch.cos(coords[:, 1] * freq)\n    \n    return pos_encoding\n\n\nprint(\"‚úÖ Graph utilities loaded\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T11:32:21.413962Z","iopub.execute_input":"2025-10-09T11:32:21.414342Z","iopub.status.idle":"2025-10-09T11:32:21.444623Z","shell.execute_reply.started":"2025-10-09T11:32:21.414317Z","shell.execute_reply":"2025-10-09T11:32:21.443731Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Graph utilities loaded\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## üìä Section 4: Multi-Scenario Data Loader\n\n*Same as previous - unchanged*","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# üìä SECTION 4: MULTI-SCENARIO DATA LOADER (SAME AS BEFORE)\n# ============================================================================\n\nclass ClimateDatasetWithScenario(Dataset):\n    \"\"\"PyTorch dataset with scenario information.\"\"\"\n    \n    def __init__(self, X: np.ndarray, y: np.ndarray, scenarios: np.ndarray):\n        self.X = torch.from_numpy(X.astype(np.float32))\n        self.y = torch.from_numpy(y.astype(np.float32))\n        self.scenarios = torch.from_numpy(scenarios.astype(np.float32))\n    \n    def __len__(self):\n        return self.X.shape[0]\n    \n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx], self.scenarios[idx]\n\n\nclass MultiScenarioDataLoader:\n    \"\"\"Multi-Scenario Data Loader for STGNN.\"\"\"\n    \n    def __init__(self, target_h: int = 9, target_w: int = 19):\n        self.input_base = INPUT_DATA_DIR\n        self.output_base = OUTPUT_DATA_DIR\n        self.target_h = target_h\n        self.target_w = target_w\n        self.scalers = {}\n        self.scenarios = SCENARIOS\n        self.input_variables = INPUT_VARIABLES\n        \n        self.variable_dirs = {\n            'BC_anthro_fires': 'BC_sum', 'BC_no_fires': 'BC_sum',\n            'CH4_anthro_fires': 'CH4_sum', 'CH4_no_fires': 'CH4_sum',\n            'CO2_sum': 'CO2_sum',\n            'SO2_anthro_fires': 'SO2_sum', 'SO2_no_fires': 'SO2_sum'\n        }\n        self.output_variable = OUTPUT_VARIABLE\n        print(f\"üìä DataLoader initialized: {target_h}√ó{target_w}\")\n    \n    def _matches_variable_pattern(self, filename: str, variable: str) -> bool:\n        \"\"\"Pattern matching for filenames.\"\"\"\n        f = filename.lower()\n        patterns = {\n            'BC_anthro_fires': (['bc', 'anthro'], ['fire']),\n            'BC_no_fires': (['bc', 'no'], ['fire']),\n            'CH4_anthro_fires': (['ch4', 'anthro'], ['fire']),\n            'CH4_no_fires': (['ch4', 'no'], ['fire']),\n            'CO2_sum': (['co2'], []),\n            'SO2_anthro_fires': (['so2', 'anthro'], ['fire']),\n            'SO2_no_fires': (['so2', 'no'], ['fire'])\n        }\n        \n        if variable in patterns:\n            req, opt = patterns[variable]\n            has_req = all(p in f for p in req)\n            if 'no' in req:\n                has_req = has_req and 'anthro' not in f\n            if opt:\n                return has_req and any(p in f for p in opt)\n            return has_req\n        return False\n    \n    def _is_file_readable(self, file_path: str) -> bool:\n        \"\"\"Check if file can be opened.\"\"\"\n        try:\n            if not os.path.exists(file_path) or os.path.getsize(file_path) < 1000:\n                return False\n            with xr.open_dataset(file_path, decode_times=False) as ds:\n                _ = list(ds.data_vars.keys())\n            return True\n        except:\n            return False\n    \n    def discover_files_multi_scenario(self, institution: str):\n        \"\"\"Discover files for all scenarios.\"\"\"\n        print(f\"üîç Discovering files for {institution}...\")\n        all_scenario_files = {}\n        \n        for scenario in self.scenarios.keys():\n            print(f\"   üìÅ {scenario}\")\n            results_inputs = {}\n            results_outputs = {}\n            \n            # Input files\n            for var in self.input_variables:\n                folder = self.variable_dirs.get(var, var)\n                path = os.path.join(self.input_base, scenario, folder)\n                \n                if not os.path.exists(path):\n                    continue\n                \n                found = []\n                for root, dirs, files in os.walk(path):\n                    for fname in files:\n                        if fname.endswith('.nc') and self._matches_variable_pattern(fname, var):\n                            fpath = os.path.join(root, fname)\n                            if self._is_file_readable(fpath):\n                                found.append(fpath)\n                \n                if found:\n                    results_inputs[var] = found\n                    print(f\"      ‚úì {var}: {len(found)} files\")\n            \n            # Output files\n            out_path = os.path.join(self.output_base, institution, scenario, self.output_variable)\n            if os.path.exists(out_path):\n                out_files = []\n                for root, dirs, files in os.walk(out_path):\n                    for fname in files:\n                        if fname.endswith('.nc'):\n                            fpath = os.path.join(root, fname)\n                            if self._is_file_readable(fpath):\n                                out_files.append(fpath)\n                \n                if out_files:\n                    results_outputs[self.output_variable] = out_files\n                    print(f\"      ‚úì {self.output_variable}: {len(out_files)} files\")\n            \n            all_scenario_files[scenario] = {\"inputs\": results_inputs, \"outputs\": results_outputs}\n        \n        return all_scenario_files\n    \n    def downsample_spatial(self, arr, target_h, target_w):\n        \"\"\"Downsample using scipy.ndimage.zoom.\"\"\"\n        if arr.shape[1] == target_h and arr.shape[2] == target_w:\n            return arr\n        T, H, W = arr.shape\n        downsampled = zoom(arr, [1.0, target_h/H, target_w/W], order=1, mode='nearest')\n        return downsampled[:, :target_h, :target_w]\n    \n    def _load_netcdf_list(self, paths, var_hint=None):\n        \"\"\"Load and concatenate NetCDF files.\"\"\"\n        arrays = []\n        for p in sorted(paths):\n            try:\n                ds = xr.open_dataset(p, decode_times=False)\n                dvars = list(ds.data_vars.keys())\n                if not dvars:\n                    ds.close()\n                    continue\n                var = var_hint if (var_hint and var_hint in dvars) else dvars[0]\n                arr = ds[var].values\n                ds.close()\n                if arr.ndim == 2:\n                    arr = np.expand_dims(arr, 0)\n                elif arr.ndim > 3:\n                    arr = arr.reshape(-1, arr.shape[-2], arr.shape[-1])\n                arrays.append(np.nan_to_num(arr, 0.0, 0.0, 0.0))\n            except Exception:\n                continue\n        \n        if not arrays:\n            return np.zeros((0, 0, 0), dtype=float)\n        \n        try:\n            return np.concatenate(arrays, axis=0)\n        except:\n            mh = max(a.shape[1] for a in arrays)\n            mw = max(a.shape[2] for a in arrays)\n            padded = [np.pad(a, ((0,0), (0,mh-a.shape[1]), (0,mw-a.shape[2])), 'edge') for a in arrays]\n            return np.concatenate(padded, axis=0)\n    \n    def align_temporal_dimensions(self, var_data):\n        \"\"\"Align temporal dimensions.\"\"\"\n        if not var_data:\n            return var_data\n        times = {v: a.shape[0] for v, a in var_data.items()}\n        mt = min(times.values())\n        if mt != max(times.values()):\n            print(f\"      ‚ö†Ô∏è Aligning to {mt} timesteps\")\n            return {v: a[:mt] for v, a in var_data.items()}\n        return var_data\n    \n    def load_all_scenarios(self, all_files):\n        \"\"\"Load all scenario data.\"\"\"\n        print(\"üìä Loading scenarios...\")\n        all_data = {}\n        \n        for scenario, files in all_files.items():\n            print(f\"   üìÅ {scenario}\")\n            var_data = {}\n            \n            for var, paths in files.get(\"inputs\", {}).items():\n                if paths:\n                    arr = self._load_netcdf_list(paths)\n                    if arr.size > 0:\n                        var_data[var] = arr\n                        print(f\"      ‚úì {var}: {arr.shape}\")\n            \n            for var, paths in files.get(\"outputs\", {}).items():\n                if paths:\n                    arr = self._load_netcdf_list(paths)\n                    if arr.size > 0:\n                        var_data[var] = arr\n                        print(f\"      ‚úì {var}: {arr.shape}\")\n            \n            if var_data:\n                var_data = self.align_temporal_dimensions(var_data)\n                print(f\"      üîΩ Downsampling...\")\n                down_data = {}\n                for v, a in var_data.items():\n                    d = self.downsample_spatial(a, self.target_h, self.target_w)\n                    down_data[v] = d\n                    print(f\"         {v}: {a.shape} ‚Üí {d.shape}\")\n                all_data[scenario] = down_data\n        \n        print(f\"   ‚úÖ Loaded {len(all_data)} scenarios\")\n        return all_data\n    \n    def normalize_data(self, arr, var_name, fit=True):\n        \"\"\"Normalize data.\"\"\"\n        arr = np.nan_to_num(arr, 0.0, 0.0, 0.0)\n        flat = arr.reshape(-1, 1)\n        \n        if fit or var_name not in self.scalers:\n            scaler = MinMaxScaler()\n            try:\n                scaler.fit(flat)\n            except:\n                scaler.min_, scaler.scale_ = np.min(flat), 1.0\n            self.scalers[var_name] = scaler\n        else:\n            scaler = self.scalers[var_name]\n        \n        return np.nan_to_num(scaler.transform(flat).reshape(arr.shape), 0.0, 0.0, 0.0)\n    \n    def create_multi_scenario_sequences(self, all_data, seq_in=12, seq_out=3, stride=1, \n                                       train_ratio=0.7, val_ratio=0.15, batch_size=1):\n        \"\"\"Create sequences with stratified splitting.\"\"\"\n        print(\"üîÑ Creating sequences...\")\n        X_seqs, Y_seqs, sc_ids = [], [], []\n        \n        for scenario, var_data in all_data.items():\n            if not var_data:\n                continue\n            \n            sc_id = self.scenarios[scenario]\n            print(f\"   üì¶ {scenario} (id={sc_id})\")\n            \n            missing = [v for v in self.input_variables if v not in var_data]\n            if missing or self.output_variable not in var_data:\n                print(f\"      ‚ö†Ô∏è Skipping - missing data\")\n                continue\n            \n            # Normalize\n            norm = {v: self.normalize_data(var_data[v], v, True) for v in self.input_variables if v in var_data}\n            norm[self.output_variable] = self.normalize_data(var_data[self.output_variable], \n                                                             self.output_variable, True)\n            \n            # Stack\n            X_sc = np.stack([norm[v] for v in self.input_variables if v in norm], axis=1)\n            Y_sc = norm[self.output_variable]\n            \n            T = X_sc.shape[0]\n            n_samp = T - seq_in - seq_out + 1\n            \n            if n_samp <= 0:\n                print(f\"      ‚ö†Ô∏è Not enough timesteps\")\n                continue\n            \n            for start in range(0, n_samp, stride):\n                X_seqs.append(X_sc[start:start+seq_in])\n                Y_seqs.append(Y_sc[start+seq_in:start+seq_in+seq_out])\n                sc_ids.append(sc_id)\n            \n            print(f\"      ‚úì {n_samp} sequences\")\n        \n        if not X_seqs:\n            raise RuntimeError(\"‚ùå No sequences!\")\n        \n        X_all = np.stack(X_seqs, 0)\n        Y_all = np.stack(Y_seqs, 0)\n        sc_all = np.array(sc_ids)\n        \n        # Add scenario channel\n        N, T, C, H, W = X_all.shape\n        sc_ch = np.repeat(sc_all[:, None, None, None, None], T*H*W, 1).reshape(N, T, 1, H, W)\n        X_all = np.concatenate([X_all, sc_ch], 2)\n        Y_all = np.expand_dims(Y_all, 2)\n        \n        print(f\"   üß© Total: X={X_all.shape}, Y={Y_all.shape}\")\n        \n        # Stratified split\n        print(\"   üìä Stratified split...\")\n        X_tr, X_tmp, y_tr, y_tmp, sc_tr, sc_tmp = train_test_split(\n            X_all, Y_all, sc_all, test_size=(1-train_ratio), stratify=sc_all, random_state=42\n        )\n        vt_ratio = val_ratio / (1 - train_ratio)\n        X_val, X_te, y_val, y_te, sc_val, sc_te = train_test_split(\n            X_tmp, y_tmp, sc_tmp, test_size=(1-vt_ratio), stratify=sc_tmp, random_state=42\n        )\n        \n        splits = {\n            \"train\": {\"input\": X_tr, \"target\": y_tr, \"scenarios\": sc_tr},\n            \"validation\": {\"input\": X_val, \"target\": y_val, \"scenarios\": sc_val},\n            \"test\": {\"input\": X_te, \"target\": y_te, \"scenarios\": sc_te}\n        }\n        \n        loaders = {\n            \"train\": DataLoader(ClimateDatasetWithScenario(X_tr, y_tr, sc_tr), batch_size, True, \n                               pin_memory=False, num_workers=0),\n            \"validation\": DataLoader(ClimateDatasetWithScenario(X_val, y_val, sc_val), batch_size, False,\n                                    pin_memory=False, num_workers=0),\n            \"test\": DataLoader(ClimateDatasetWithScenario(X_te, y_te, sc_te), batch_size, False,\n                              pin_memory=False, num_workers=0)\n        }\n        \n        print(f\"   üì¶ Train:{len(X_tr)} Val:{len(X_val)} Test:{len(X_te)}\")\n        return splits, loaders\n\n\nprint(\"‚úÖ Multi-scenario data loader defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T11:32:21.445581Z","iopub.execute_input":"2025-10-09T11:32:21.446208Z","iopub.status.idle":"2025-10-09T11:32:21.480627Z","shell.execute_reply.started":"2025-10-09T11:32:21.446189Z","shell.execute_reply":"2025-10-09T11:32:21.479791Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Multi-scenario data loader defined\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## üß† Section 5: Spatio-Temporal GNN Architecture\n\n**Key Innovation: Unified spatio-temporal processing**","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# üß† SECTION 5: SPATIO-TEMPORAL GNN ARCHITECTURE\n# ============================================================================\n\nclass TemporalConv(nn.Module):\n    \"\"\"\n    Temporal Convolution with causal padding.\n    Processes time dimension with 1D convolution.\n    \"\"\"\n    \n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int = 3):\n        super().__init__()\n        self.kernel_size = kernel_size\n        # Causal padding: only look at past\n        self.padding = (kernel_size - 1)\n        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, padding=self.padding)\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Args:\n            x: [batch, nodes, time, features]\n        Returns:\n            x: [batch, nodes, time, features]\n        \"\"\"\n        batch, nodes, time, features = x.shape\n        \n        # Reshape for 1D conv: [batch * nodes, features, time]\n        x = x.reshape(batch * nodes, time, features).permute(0, 2, 1)\n        \n        # Apply temporal convolution\n        x = self.conv(x)\n        \n        # Remove future timesteps (causal)\n        if self.padding > 0:\n            x = x[:, :, :-self.padding]\n        \n        # Reshape back: [batch, nodes, time, features]\n        x = x.permute(0, 2, 1).reshape(batch, nodes, time, features)\n        \n        return x\n\n\nclass SpatialGraphConv(nn.Module):\n    \"\"\"\n    Spatial Graph Convolution.\n    Processes spatial dimension with graph convolution.\n    \"\"\"\n    \n    def __init__(self, in_channels: int, out_channels: int):\n        super().__init__()\n        self.conv = GCNConv(in_channels, out_channels)\n        self.bn = nn.BatchNorm1d(out_channels)\n    \n    def forward(self, x: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Args:\n            x: [batch * time, nodes, features]\n            edge_index: [2, num_edges]\n        Returns:\n            x: [batch * time, nodes, features]\n        \"\"\"\n        batch_time, nodes, features = x.shape\n        \n        # Reshape for graph conv: [batch_time * nodes, features]\n        x = x.reshape(batch_time * nodes, features)\n        \n        # Apply graph convolution\n        x = self.conv(x, edge_index)\n        x = self.bn(x)\n        x = F.relu(x)\n        \n        # Reshape back: [batch_time, nodes, features]\n        x = x.reshape(batch_time, nodes, features)\n        \n        return x\n\n\nclass STGNNBlock(nn.Module):\n    \"\"\"\n    Spatio-Temporal Graph Neural Network Block.\n    \n    Combines:\n    1. Temporal Convolution (captures temporal patterns)\n    2. Spatial Graph Convolution (captures spatial patterns)\n    3. Residual connection + Layer Norm\n    \"\"\"\n    \n    def __init__(self, hidden_dim: int, temporal_kernel: int = 3, dropout: float = 0.2):\n        super().__init__()\n        \n        self.temporal_conv = TemporalConv(hidden_dim, hidden_dim, temporal_kernel)\n        self.spatial_conv = SpatialGraphConv(hidden_dim, hidden_dim)\n        \n        self.layer_norm1 = nn.LayerNorm(hidden_dim)\n        self.layer_norm2 = nn.LayerNorm(hidden_dim)\n        \n        self.dropout = nn.Dropout(dropout)\n        \n        # FFN\n        self.ffn = nn.Sequential(\n            nn.Linear(hidden_dim, hidden_dim * 2),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim * 2, hidden_dim),\n            nn.Dropout(dropout)\n        )\n        self.layer_norm3 = nn.LayerNorm(hidden_dim)\n    \n    def forward(self, x: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Args:\n            x: [batch, nodes, time, features]\n            edge_index: [2, num_edges]\n        Returns:\n            x: [batch, nodes, time, features]\n        \"\"\"\n        batch, nodes, time, features = x.shape\n        \n        # 1. Temporal convolution with residual\n        identity = x\n        x_temporal = self.temporal_conv(x)\n        x_temporal = self.dropout(x_temporal)\n        x = self.layer_norm1(identity + x_temporal)\n        \n        # 2. Spatial graph convolution with residual\n        identity = x\n        # Reshape for spatial processing: [batch * time, nodes, features]\n        x_spatial = x.permute(0, 2, 1, 3).reshape(batch * time, nodes, features)\n        x_spatial = self.spatial_conv(x_spatial, edge_index)\n        x_spatial = self.dropout(x_spatial)\n        # Reshape back: [batch, nodes, time, features]\n        x_spatial = x_spatial.reshape(batch, time, nodes, features).permute(0, 2, 1, 3)\n        x = self.layer_norm2(identity + x_spatial)\n        \n        # 3. Feed-forward network with residual\n        identity = x\n        x_ffn = self.ffn(x)\n        x = self.layer_norm3(identity + x_ffn)\n        \n        return x\n\n\nclass STGNNPredictor(nn.Module):\n    \"\"\"\n    Complete Spatio-Temporal GNN for Climate Prediction.\n    \n    Architecture:\n    1. Input embedding (8 channels ‚Üí hidden_dim)\n    2. Positional encoding\n    3. Multiple STGNN blocks\n    4. Temporal projection (12 ‚Üí 3 timesteps)\n    5. Output projection (hidden_dim ‚Üí 1)\n    \"\"\"\n    \n    def __init__(self,\n                 input_channels: int = 8,\n                 hidden_dim: int = 64,\n                 num_blocks: int = 3,\n                 temporal_kernel: int = 3,\n                 spatial_size: Tuple[int, int] = (9, 19),\n                 input_length: int = 12,\n                 output_length: int = 3,\n                 dropout: float = 0.2):\n        super().__init__()\n        \n        self.input_channels = input_channels\n        self.hidden_dim = hidden_dim\n        self.num_blocks = num_blocks\n        self.spatial_size = spatial_size\n        self.num_nodes = spatial_size[0] * spatial_size[1]\n        self.input_length = input_length\n        self.output_length = output_length\n        \n        print(f\"üîß Initializing STGNN Predictor:\")\n        print(f\"   Input: {input_length} timesteps √ó {input_channels} channels √ó {spatial_size[0]}√ó{spatial_size[1]}\")\n        print(f\"   Hidden: {hidden_dim}, Blocks: {num_blocks}\")\n        print(f\"   Output: {output_length} timesteps\")\n        \n        # Build graph structure\n        self.edge_index = build_grid_graph_8neighbor(spatial_size[0], spatial_size[1])\n        self.edge_index = add_self_loops(self.edge_index, self.num_nodes)\n        \n        # Positional encoding\n        self.pos_encoding = get_positional_encoding(spatial_size[0], spatial_size[1], hidden_dim)\n        \n        # Input embedding\n        self.input_embed = nn.Linear(input_channels, hidden_dim)\n        \n        # STGNN blocks\n        self.stgnn_blocks = nn.ModuleList([\n            STGNNBlock(hidden_dim, temporal_kernel, dropout)\n            for _ in range(num_blocks)\n        ])\n        \n        # Temporal projection: 12 timesteps ‚Üí 3 timesteps\n        # self.temporal_proj = nn.Conv1d(input_length, output_length, kernel_size=1)\n        self.temporal_proj = nn.Linear(self.input_length, self.output_length)\n        \n        # Output projection\n        self.output_proj = nn.Sequential(\n            nn.Linear(hidden_dim, hidden_dim // 2),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim // 2, 1)\n        )\n        \n        # Non-negative activation for precipitation\n        self.output_activation = nn.Softplus(beta=10)\n        \n        num_params = sum(p.numel() for p in self.parameters())\n        print(f\"‚úÖ STGNN initialized - Parameters: {num_params:,}\")\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Args:\n            x: [batch, seq_len, channels, height, width]\n        Returns:\n            predictions: [batch, output_length, 1, height, width]\n        \"\"\"\n        batch_size, seq_len, channels, height, width = x.shape\n        edge_index = self.edge_index.to(x.device)\n        \n        # Reshape to [batch, nodes, time, channels]\n        x = x.permute(0, 1, 3, 4, 2)  # [batch, time, height, width, channels]\n        x = x.reshape(batch_size, seq_len, self.num_nodes, channels)\n        x = x.permute(0, 2, 1, 3)  # [batch, nodes, time, channels]\n        \n        # Input embedding\n        x = self.input_embed(x)  # [batch, nodes, time, hidden_dim]\n        \n        # Add positional encoding\n        pos_enc = self.pos_encoding.to(x.device)  # [nodes, hidden_dim]\n        pos_enc = pos_enc.unsqueeze(0).unsqueeze(2)  # [1, nodes, 1, hidden_dim]\n        x = x + pos_enc\n        \n        # Process through STGNN blocks\n        for block in self.stgnn_blocks:\n            x = block(x, edge_index)\n        \n        # x shape: [batch, nodes, time, hidden_dim]\n        \n        # Temporal projection: 12 ‚Üí 3 timesteps\n        # x_temp: [batch * nodes, time, hidden_dim]\n        x_temp = x.reshape(batch_size * self.num_nodes, seq_len, self.hidden_dim)\n        \n        # Permute to [batch*nodes, hidden_dim, time] so Linear acts on last dim=time\n        x_temp = x_temp.permute(0, 2, 1)  # [B*N, hidden_dim, seq_len]\n        \n        # Apply Linear to the time axis: Linear(seq_len -> output_length)\n        # The Linear acts on the last dimension (seq_len) and returns [B*N, hidden_dim, output_length]\n        x_temp = self.temporal_proj(x_temp)\n        \n        # Permute and reshape to [batch, nodes, output_length, hidden_dim]\n        x_temp = x_temp.permute(0, 2, 1).reshape(batch_size, self.num_nodes, self.output_length, self.hidden_dim)\n\n        \n        # Output projection\n        predictions = self.output_proj(x_temp)  # [batch, nodes, output_length, 1]\n        predictions = self.output_activation(predictions)\n        \n        # Reshape to [batch, output_length, 1, height, width]\n        predictions = predictions.squeeze(-1)  # [batch, nodes, output_length]\n        predictions = predictions.reshape(batch_size, height, width, self.output_length)\n        predictions = predictions.permute(0, 3, 1, 2).unsqueeze(2)  # [batch, output_length, 1, height, width]\n        \n        return predictions\n\n\nprint(\"‚úÖ STGNN architecture defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T11:32:21.481289Z","iopub.execute_input":"2025-10-09T11:32:21.481500Z","iopub.status.idle":"2025-10-09T11:32:21.503870Z","shell.execute_reply.started":"2025-10-09T11:32:21.481485Z","shell.execute_reply":"2025-10-09T11:32:21.503347Z"}},"outputs":[{"name":"stdout","text":"‚úÖ STGNN architecture defined\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## üöÇ Section 6: Training Function\n\n*Updated for STGNN model*","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# üöÇ SECTION 6: TRAINING FUNCTION FOR STGNN\n# ============================================================================\n\ndef train_single_institution_multi_scenario(institution: str) -> dict:\n    \"\"\"Train STGNN for single institution with multi-scenario data.\"\"\"\n    \n    print(f\"\\n{'='*80}\")\n    print(f\"üåê Training STGNN: {institution}\")\n    print(f\"{'='*80}\")\n    \n    start_time = time.time()\n    \n    model_path = os.path.join(OUTPUT_DIR, \"checkpoints\", f\"{institution}_stgnn_multiscenario_best.pt\")\n    \n    if RESUME_IF_MODEL_EXISTS and os.path.exists(model_path):\n        print(f\"‚≠ê Model exists - skipping {institution}\")\n        return {'success': True, 'institution': institution, 'skipped': True}\n    \n    try:\n        # Data loader\n        print(\"üìä Step 1/7: Initializing data loader...\")\n        dl = MultiScenarioDataLoader(target_h=TARGET_SPATIAL_H, target_w=TARGET_SPATIAL_W)\n        \n        # Discover files\n        print(\"üîç Step 2/7: Discovering files...\")\n        all_scenario_files = dl.discover_files_multi_scenario(institution)\n        \n        has_data = any(\n            bool(files['inputs']) or bool(files['outputs'])\n            for files in all_scenario_files.values()\n        )\n        \n        if not has_data:\n            print(f\"‚ö†Ô∏è No data for {institution}\")\n            return {'success': False, 'institution': institution, 'error': 'No data'}\n        \n        # Load scenarios\n        print(\"üìä Step 3/7: Loading data...\")\n        all_scenario_data = dl.load_all_scenarios(all_scenario_files)\n        \n        if not all_scenario_data:\n            print(f\"‚ö†Ô∏è Failed to load data\")\n            return {'success': False, 'institution': institution, 'error': 'Load failed'}\n        \n        # Create sequences\n        print(\"üîÑ Step 4/7: Creating sequences...\")\n        data_splits, dataloaders = dl.create_multi_scenario_sequences(all_scenario_data)\n        \n        # Create STGNN model\n        print(\"üß† Step 5/7: Creating STGNN model...\")\n        model = STGNNPredictor(\n            input_channels=NUM_INPUT_CHANNELS,\n            hidden_dim=HIDDEN_DIM,\n            num_blocks=STGNN_BLOCKS,\n            temporal_kernel=TEMPORAL_KERNEL_SIZE,\n            spatial_size=(TARGET_SPATIAL_H, TARGET_SPATIAL_W),\n            input_length=12,\n            output_length=3,\n            dropout=DROPOUT\n        ).to(device)\n        \n        optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.05)\n        criterion = nn.MSELoss()\n        \n        history = {\n            'train_loss': [],\n            'val_loss': [],\n            'scenario_losses': {}\n        }\n        best_val_loss = float('inf')\n        \n        print(f\"\\nüöÇ Step 6/7: Training for {EPOCHS} epochs...\")\n        \n        epoch_pbar = tqdm(range(EPOCHS), desc=f\"üåê {institution}\", position=0, leave=True)\n        \n        for ep in epoch_pbar:\n            # Training\n            model.train()\n            train_loss = 0.0\n            train_batches = 0\n            \n            for X, y, scenarios in dataloaders['train']:\n                try:\n                    X, y = X.to(device), y.to(device)\n                    optimizer.zero_grad()\n                    preds = model(X)\n                    \n                    if preds.shape != y.shape:\n                        if preds.ndim == 4 and y.ndim == 5:\n                            preds = preds.unsqueeze(2)\n                    \n                    loss = criterion(preds, y)\n                    loss.backward()\n                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n                    optimizer.step()\n                    \n                    train_loss += loss.item()\n                    train_batches += 1\n                    \n                    if train_batches % 10 == 0:\n                        torch.cuda.empty_cache()\n                except Exception as e:\n                    print(f\"\\n‚ùå Training error: {e}\")\n                    continue\n            \n            avg_train_loss = train_loss / max(1, train_batches)\n            history['train_loss'].append(avg_train_loss)\n            \n            # Validation\n            model.eval()\n            val_loss = 0.0\n            val_batches = 0\n            scenario_losses = {s: [] for s in SCENARIOS.keys()}\n            \n            with torch.no_grad():\n                for Xv, yv, scenarios_v in dataloaders['validation']:\n                    try:\n                        Xv, yv = Xv.to(device), yv.to(device)\n                        preds = model(Xv)\n                        \n                        if preds.shape != yv.shape:\n                            if preds.ndim == 4 and yv.ndim == 5:\n                                preds = preds.unsqueeze(2)\n                        \n                        batch_loss = criterion(preds, yv)\n                        val_loss += batch_loss.item()\n                        val_batches += 1\n                        \n                        # Track per-scenario\n                        for i, scenario_id in enumerate(scenarios_v.cpu().numpy()):\n                            scenario_name = [k for k, v in SCENARIOS.items() if v == scenario_id][0]\n                            scenario_losses[scenario_name].append(batch_loss.item())\n                    except Exception as e:\n                        print(f\"\\n‚ùå Validation error: {e}\")\n                        continue\n            \n            avg_val_loss = val_loss / max(1, val_batches)\n            history['val_loss'].append(avg_val_loss)\n            \n            avg_scenario_losses = {\n                s: np.mean(losses) if losses else 0.0\n                for s, losses in scenario_losses.items()\n            }\n            history['scenario_losses'][f'epoch_{ep+1}'] = avg_scenario_losses\n            \n            is_best = avg_val_loss < best_val_loss\n            if is_best:\n                best_val_loss = avg_val_loss\n                best_indicator = \"‚≠ê NEW BEST\"\n            else:\n                best_indicator = \"\"\n            \n            epoch_pbar.set_postfix({\n                'train': f'{avg_train_loss:.6f}',\n                'val': f'{avg_val_loss:.6f}',\n                'best': f'{best_val_loss:.6f}',\n                'status': best_indicator\n            })\n            \n            if ep % 3 == 0:\n                torch.cuda.empty_cache()\n                gc.collect()\n        \n        epoch_pbar.close()\n        \n        # Save model\n        print(\"üíæ Step 7/7: Saving model...\")\n        torch.save({\n            'institution': institution,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'history': history,\n            'best_val_loss': best_val_loss,\n            'spatial_dims': [TARGET_SPATIAL_H, TARGET_SPATIAL_W],\n            'scenarios': list(SCENARIOS.keys()),\n            'timestamp': datetime.now().isoformat()\n        }, model_path)\n        \n        # Save results\n        summary = {\n            'institution': institution,\n            'training_time': time.time() - start_time,\n            'epochs_trained': len(history['train_loss']),\n            'best_val_loss': best_val_loss,\n            'spatial_dims': [TARGET_SPATIAL_H, TARGET_SPATIAL_W],\n            'scenarios': list(SCENARIOS.keys()),\n            'final_scenario_losses': history['scenario_losses'].get(f'epoch_{EPOCHS}', {}),\n            'timestamp': datetime.now().isoformat()\n        }\n        \n        results_path = os.path.join(OUTPUT_DIR, \"logs\", f\"{institution}_stgnn_phase4_results.json\")\n        with open(results_path, 'w') as f:\n            json.dump(summary, f, indent=2)\n        \n        return {'success': True, 'institution': institution, 'results': summary}\n    \n    except Exception as e:\n        print(f\"\\n‚ùå FATAL ERROR: {e}\")\n        import traceback\n        traceback.print_exc()\n        return {'success': False, 'institution': institution, 'error': str(e)}\n    \n    finally:\n        torch.cuda.empty_cache()\n        gc.collect()\n\n\nprint(\"‚úÖ Training function defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T11:32:21.504817Z","iopub.execute_input":"2025-10-09T11:32:21.505568Z","iopub.status.idle":"2025-10-09T11:32:21.525940Z","shell.execute_reply.started":"2025-10-09T11:32:21.505542Z","shell.execute_reply":"2025-10-09T11:32:21.525200Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Training function defined\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## üöÄ Section 7: Main Training Loop\n\n*Same structure, updated for STGNN*","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# üöÄ SECTION 7: MAIN TRAINING EXECUTION\n# ============================================================================\n\nprint(\"=\"*80)\nprint(\"üåê STGNN Phase 4 - Multi-Scenario Training\")\nprint(\"=\"*80)\nprint(f\"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\nsys.stdout.flush()\n\n# Determine institutions\nif SMOKE_TEST:\n    institutions = ALL_INSTITUTIONS[:2]\n    print(f\"‚ö†Ô∏è SMOKE TEST - Training only {len(institutions)} institutions\")\nelse:\n    institutions = ALL_INSTITUTIONS\n    print(f\"üìã Training all {len(institutions)} institutions\")\n\nprint(f\"   Model: Spatio-Temporal GNN\")\nprint(f\"   Scenarios: {list(SCENARIOS.keys())}\")\nprint(f\"   Spatial: {TARGET_SPATIAL_H}√ó{TARGET_SPATIAL_W}\")\nprint(f\"   STGNN Blocks: {STGNN_BLOCKS}\")\nprint(f\"   Batch size: {BATCH_SIZE}\")\nprint(f\"   Epochs: {EPOCHS}\")\nprint(f\"   Input channels: {NUM_INPUT_CHANNELS}\")\nsys.stdout.flush()\n\nif torch.cuda.is_available():\n    print(f\"\\nüéÆ GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.1f} GB\")\n\nif SKIP_TRAINING:\n    print(\"SKIP_TRAINING=True - Loading existing results...\")\n    summary_path = os.path.join(OUTPUT_DIR, \"logs\", \"stgnn_phase4_training_summary.json\")\n    if os.path.exists(summary_path):\n        with open(summary_path, 'r') as f:\n            summary = json.load(f)\n        print(\"‚úÖ Loaded existing results\")\n    else:\n        summary = {}\nelse:\n    print(\"\\n\" + \"=\"*80)\n    print(\"üöÇ STARTING TRAINING\")\n    print(\"=\"*80)\n    sys.stdout.flush()\n    \n    t0 = time.time()\n    all_results = []\n    \n    main_pbar = tqdm(institutions, desc=\"üåê Overall\", position=0)\n    \n    for inst_idx, institution in enumerate(main_pbar):\n        print(f\"\\n{'='*80}\")\n        print(f\"Institution {inst_idx+1}/{len(institutions)}: {institution}\")\n        print(f\"{'='*80}\")\n        sys.stdout.flush()\n        \n        try:\n            result = train_single_institution_multi_scenario(institution)\n            all_results.append(result)\n            \n            successful = sum(1 for r in all_results if r.get('success') and not r.get('skipped'))\n            skipped = sum(1 for r in all_results if r.get('skipped'))\n            failed = sum(1 for r in all_results if not r.get('success'))\n            \n            main_pbar.set_postfix({\n                'success': successful,\n                'skipped': skipped,\n                'failed': failed\n            })\n            \n            # Save progress\n            progress = {\n                'completed': len(all_results),\n                'total': len(institutions),\n                'results': all_results,\n                'timestamp': datetime.now().isoformat()\n            }\n            \n            progress_path = os.path.join(OUTPUT_DIR, \"logs\", \"stgnn_phase4_progress.json\")\n            with open(progress_path, 'w') as f:\n                json.dump(progress, f, indent=2)\n        \n        except Exception as e:\n            print(f\"\\n‚ùå CRITICAL ERROR: {e}\")\n            all_results.append({\n                'success': False,\n                'institution': institution,\n                'error': str(e)\n            })\n    \n    main_pbar.close()\n    elapsed = time.time() - t0\n    \n    # Summary\n    successful = [r for r in all_results if r.get('success') and not r.get('skipped')]\n    skipped = [r for r in all_results if r.get('skipped')]\n    failed = [r for r in all_results if not r.get('success')]\n    \n    summary = {\n        'model_type': 'STGNN',\n        'phase': 'phase4_multi_scenario',\n        'total_institutions': len(institutions),\n        'successful': len(successful),\n        'skipped': len(skipped),\n        'failed': len(failed),\n        'total_time_hours': elapsed / 3600,\n        'scenarios': list(SCENARIOS.keys()),\n        'results': all_results,\n        'timestamp': datetime.now().isoformat()\n    }\n    \n    summary_path = os.path.join(OUTPUT_DIR, \"logs\", \"stgnn_phase4_training_summary.json\")\n    with open(summary_path, 'w') as f:\n        json.dump(summary, f, indent=2)\n    \n    print(f\"\\n{'='*80}\")\n    print(\"‚úÖ STGNN Phase 4 Training Complete!\")\n    print(f\"{'='*80}\")\n    print(f\"Total: {len(institutions)}\")\n    print(f\"  ‚úÖ Successful: {len(successful)}\")\n    print(f\"  ‚≠ê Skipped: {len(skipped)}\")\n    print(f\"  ‚ùå Failed: {len(failed)}\")\n    print(f\"Total time: {elapsed/3600:.2f} hours\")\n    print(f\"{'='*80}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T11:32:21.527793Z","iopub.execute_input":"2025-10-09T11:32:21.527987Z","iopub.status.idle":"2025-10-09T11:50:49.300331Z","shell.execute_reply.started":"2025-10-09T11:32:21.527972Z","shell.execute_reply":"2025-10-09T11:50:49.299470Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nüåê STGNN Phase 4 - Multi-Scenario Training\n================================================================================\nStart time: 2025-10-09 11:32:21\n‚ö†Ô∏è SMOKE TEST - Training only 2 institutions\n   Model: Spatio-Temporal GNN\n   Scenarios: ['historical', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n   Spatial: 9√ó19\n   STGNN Blocks: 3\n   Batch size: 1\n   Epochs: 2\n   Input channels: 8\n\nüéÆ GPU: Tesla P100-PCIE-16GB\n   Memory: 15.9 GB\n\n================================================================================\nüöÇ STARTING TRAINING\n================================================================================\n","output_type":"stream"},{"name":"stderr","text":"üåê Overall:   0%|          | 0/2 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\n================================================================================\nInstitution 1/2: AWI-CM-1-1-MR\n================================================================================\n\n================================================================================\nüåê Training STGNN: AWI-CM-1-1-MR\n================================================================================\nüìä Step 1/7: Initializing data loader...\nüìä DataLoader initialized: 9√ó19\nüîç Step 2/7: Discovering files...\nüîç Discovering files for AWI-CM-1-1-MR...\n   üìÅ historical\n      ‚úì BC_anthro_fires: 165 files\n      ‚úì BC_no_fires: 165 files\n      ‚úì CH4_anthro_fires: 165 files\n      ‚úì CH4_no_fires: 165 files\n      ‚úì CO2_sum: 165 files\n      ‚úì SO2_anthro_fires: 165 files\n      ‚úì SO2_no_fires: 165 files\n      ‚úì pr: 165 files\n   üìÅ ssp126\n      ‚úì BC_anthro_fires: 86 files\n      ‚úì BC_no_fires: 86 files\n      ‚úì CH4_anthro_fires: 86 files\n      ‚úì CH4_no_fires: 86 files\n      ‚úì CO2_sum: 86 files\n      ‚úì SO2_anthro_fires: 86 files\n      ‚úì SO2_no_fires: 86 files\n      ‚úì pr: 86 files\n   üìÅ ssp245\n      ‚úì BC_anthro_fires: 86 files\n      ‚úì BC_no_fires: 86 files\n      ‚úì CH4_anthro_fires: 86 files\n      ‚úì CH4_no_fires: 86 files\n      ‚úì CO2_sum: 86 files\n      ‚úì SO2_anthro_fires: 86 files\n      ‚úì SO2_no_fires: 86 files\n      ‚úì pr: 86 files\n   üìÅ ssp370\n      ‚úì BC_anthro_fires: 86 files\n      ‚úì BC_no_fires: 86 files\n      ‚úì CH4_anthro_fires: 86 files\n      ‚úì CH4_no_fires: 86 files\n      ‚úì CO2_sum: 86 files\n      ‚úì SO2_anthro_fires: 86 files\n      ‚úì SO2_no_fires: 86 files\n      ‚úì pr: 86 files\n   üìÅ ssp585\n      ‚úì BC_anthro_fires: 86 files\n      ‚úì BC_no_fires: 86 files\n      ‚úì CH4_anthro_fires: 86 files\n      ‚úì CH4_no_fires: 86 files\n      ‚úì CO2_sum: 86 files\n      ‚úì SO2_anthro_fires: 86 files\n      ‚úì SO2_no_fires: 86 files\n      ‚úì pr: 86 files\nüìä Step 3/7: Loading data...\nüìä Loading scenarios...\n   üìÅ historical\n      ‚úì BC_anthro_fires: (1980, 96, 144)\n      ‚úì BC_no_fires: (1980, 96, 144)\n      ‚úì CH4_anthro_fires: (1980, 96, 144)\n      ‚úì CH4_no_fires: (1980, 96, 144)\n      ‚úì CO2_sum: (1980, 96, 144)\n      ‚úì SO2_anthro_fires: (1980, 96, 144)\n      ‚úì SO2_no_fires: (1980, 96, 144)\n      ‚úì pr: (1980, 96, 144)\n      üîΩ Downsampling...\n         BC_anthro_fires: (1980, 96, 144) ‚Üí (1980, 9, 19)\n         BC_no_fires: (1980, 96, 144) ‚Üí (1980, 9, 19)\n         CH4_anthro_fires: (1980, 96, 144) ‚Üí (1980, 9, 19)\n         CH4_no_fires: (1980, 96, 144) ‚Üí (1980, 9, 19)\n         CO2_sum: (1980, 96, 144) ‚Üí (1980, 9, 19)\n         SO2_anthro_fires: (1980, 96, 144) ‚Üí (1980, 9, 19)\n         SO2_no_fires: (1980, 96, 144) ‚Üí (1980, 9, 19)\n         pr: (1980, 96, 144) ‚Üí (1980, 9, 19)\n   üìÅ ssp126\n      ‚úì BC_anthro_fires: (1032, 96, 144)\n      ‚úì BC_no_fires: (1032, 96, 144)\n      ‚úì CH4_anthro_fires: (1032, 96, 144)\n      ‚úì CH4_no_fires: (1032, 96, 144)\n      ‚úì CO2_sum: (1032, 96, 144)\n      ‚úì SO2_anthro_fires: (1032, 96, 144)\n      ‚úì SO2_no_fires: (1032, 96, 144)\n      ‚úì pr: (1032, 96, 144)\n      üîΩ Downsampling...\n         BC_anthro_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         BC_no_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         CH4_anthro_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         CH4_no_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         CO2_sum: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         SO2_anthro_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         SO2_no_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         pr: (1032, 96, 144) ‚Üí (1032, 9, 19)\n   üìÅ ssp245\n      ‚úì BC_anthro_fires: (1032, 96, 144)\n      ‚úì BC_no_fires: (1032, 96, 144)\n      ‚úì CH4_anthro_fires: (1032, 96, 144)\n      ‚úì CH4_no_fires: (1032, 96, 144)\n      ‚úì CO2_sum: (1032, 96, 144)\n      ‚úì SO2_anthro_fires: (1032, 96, 144)\n      ‚úì SO2_no_fires: (1032, 96, 144)\n      ‚úì pr: (1032, 96, 144)\n      üîΩ Downsampling...\n         BC_anthro_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         BC_no_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         CH4_anthro_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         CH4_no_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         CO2_sum: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         SO2_anthro_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         SO2_no_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         pr: (1032, 96, 144) ‚Üí (1032, 9, 19)\n   üìÅ ssp370\n      ‚úì BC_anthro_fires: (1032, 96, 144)\n      ‚úì BC_no_fires: (1032, 96, 144)\n      ‚úì CH4_anthro_fires: (1032, 96, 144)\n      ‚úì CH4_no_fires: (1032, 96, 144)\n      ‚úì CO2_sum: (1032, 96, 144)\n      ‚úì SO2_anthro_fires: (1032, 96, 144)\n      ‚úì SO2_no_fires: (1032, 96, 144)\n      ‚úì pr: (1032, 96, 144)\n      üîΩ Downsampling...\n         BC_anthro_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         BC_no_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         CH4_anthro_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         CH4_no_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         CO2_sum: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         SO2_anthro_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         SO2_no_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         pr: (1032, 96, 144) ‚Üí (1032, 9, 19)\n   üìÅ ssp585\n      ‚úì BC_anthro_fires: (1032, 96, 144)\n      ‚úì BC_no_fires: (1032, 96, 144)\n      ‚úì CH4_anthro_fires: (1032, 96, 144)\n      ‚úì CH4_no_fires: (1032, 96, 144)\n      ‚úì CO2_sum: (1032, 96, 144)\n      ‚úì SO2_anthro_fires: (1032, 96, 144)\n      ‚úì SO2_no_fires: (1032, 96, 144)\n      ‚úì pr: (1032, 96, 144)\n      üîΩ Downsampling...\n         BC_anthro_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         BC_no_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         CH4_anthro_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         CH4_no_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         CO2_sum: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         SO2_anthro_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         SO2_no_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         pr: (1032, 96, 144) ‚Üí (1032, 9, 19)\n   ‚úÖ Loaded 5 scenarios\nüîÑ Step 4/7: Creating sequences...\nüîÑ Creating sequences...\n   üì¶ historical (id=0)\n      ‚úì 1966 sequences\n   üì¶ ssp126 (id=1)\n      ‚úì 1018 sequences\n   üì¶ ssp245 (id=2)\n      ‚úì 1018 sequences\n   üì¶ ssp370 (id=3)\n      ‚úì 1018 sequences\n   üì¶ ssp585 (id=4)\n      ‚úì 1018 sequences\n   üß© Total: X=(6038, 12, 8, 9, 19), Y=(6038, 3, 1, 9, 19)\n   üìä Stratified split...\n   üì¶ Train:4226 Val:905 Test:907\nüß† Step 5/7: Creating STGNN model...\nüîß Initializing STGNN Predictor:\n   Input: 12 timesteps √ó 8 channels √ó 9√ó19\n   Hidden: 64, Blocks: 3\n   Output: 3 timesteps\nüìä Graph: 9√ó19 = 171 nodes, 1204 edges\n   Avg degree: 7.04\n‚úÖ STGNN initialized - Parameters: 103,528\n\nüöÇ Step 6/7: Training for 2 epochs...\n","output_type":"stream"},{"name":"stderr","text":"üåê AWI-CM-1-1-MR: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [01:53<00:00, 56.77s/it, train=0.005311, val=0.008635, best=0.008081, status=]           \nüåê Overall:   0%|          | 0/2 [09:41<?, ?it/s, success=1, skipped=0, failed=0]","output_type":"stream"},{"name":"stdout","text":"üíæ Step 7/7: Saving model...\n","output_type":"stream"},{"name":"stderr","text":"üåê Overall:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [09:41<09:41, 581.77s/it, success=1, skipped=0, failed=0]","output_type":"stream"},{"name":"stdout","text":"\n================================================================================\nInstitution 2/2: BCC-CSM2-MR\n================================================================================\n\n================================================================================\nüåê Training STGNN: BCC-CSM2-MR\n================================================================================\nüìä Step 1/7: Initializing data loader...\nüìä DataLoader initialized: 9√ó19\nüîç Step 2/7: Discovering files...\nüîç Discovering files for BCC-CSM2-MR...\n   üìÅ historical\n      ‚úì BC_anthro_fires: 165 files\n      ‚úì BC_no_fires: 165 files\n      ‚úì CH4_anthro_fires: 165 files\n      ‚úì CH4_no_fires: 165 files\n      ‚úì CO2_sum: 165 files\n      ‚úì SO2_anthro_fires: 165 files\n      ‚úì SO2_no_fires: 165 files\n      ‚úì pr: 165 files\n   üìÅ ssp126\n      ‚úì BC_anthro_fires: 86 files\n      ‚úì BC_no_fires: 86 files\n      ‚úì CH4_anthro_fires: 86 files\n      ‚úì CH4_no_fires: 86 files\n      ‚úì CO2_sum: 86 files\n      ‚úì SO2_anthro_fires: 86 files\n      ‚úì SO2_no_fires: 86 files\n      ‚úì pr: 86 files\n   üìÅ ssp245\n      ‚úì BC_anthro_fires: 86 files\n      ‚úì BC_no_fires: 86 files\n      ‚úì CH4_anthro_fires: 86 files\n      ‚úì CH4_no_fires: 86 files\n      ‚úì CO2_sum: 86 files\n      ‚úì SO2_anthro_fires: 86 files\n      ‚úì SO2_no_fires: 86 files\n      ‚úì pr: 86 files\n   üìÅ ssp370\n      ‚úì BC_anthro_fires: 86 files\n      ‚úì BC_no_fires: 86 files\n      ‚úì CH4_anthro_fires: 86 files\n      ‚úì CH4_no_fires: 86 files\n      ‚úì CO2_sum: 86 files\n      ‚úì SO2_anthro_fires: 86 files\n      ‚úì SO2_no_fires: 86 files\n      ‚úì pr: 86 files\n   üìÅ ssp585\n      ‚úì BC_anthro_fires: 86 files\n      ‚úì BC_no_fires: 86 files\n      ‚úì CH4_anthro_fires: 86 files\n      ‚úì CH4_no_fires: 86 files\n      ‚úì CO2_sum: 86 files\n      ‚úì SO2_anthro_fires: 86 files\n      ‚úì SO2_no_fires: 86 files\n      ‚úì pr: 86 files\nüìä Step 3/7: Loading data...\nüìä Loading scenarios...\n   üìÅ historical\n      ‚úì BC_anthro_fires: (1980, 96, 144)\n      ‚úì BC_no_fires: (1980, 96, 144)\n      ‚úì CH4_anthro_fires: (1980, 96, 144)\n      ‚úì CH4_no_fires: (1980, 96, 144)\n      ‚úì CO2_sum: (1980, 96, 144)\n      ‚úì SO2_anthro_fires: (1980, 96, 144)\n      ‚úì SO2_no_fires: (1980, 96, 144)\n      ‚úì pr: (1980, 96, 144)\n      üîΩ Downsampling...\n         BC_anthro_fires: (1980, 96, 144) ‚Üí (1980, 9, 19)\n         BC_no_fires: (1980, 96, 144) ‚Üí (1980, 9, 19)\n         CH4_anthro_fires: (1980, 96, 144) ‚Üí (1980, 9, 19)\n         CH4_no_fires: (1980, 96, 144) ‚Üí (1980, 9, 19)\n         CO2_sum: (1980, 96, 144) ‚Üí (1980, 9, 19)\n         SO2_anthro_fires: (1980, 96, 144) ‚Üí (1980, 9, 19)\n         SO2_no_fires: (1980, 96, 144) ‚Üí (1980, 9, 19)\n         pr: (1980, 96, 144) ‚Üí (1980, 9, 19)\n   üìÅ ssp126\n      ‚úì BC_anthro_fires: (1032, 96, 144)\n      ‚úì BC_no_fires: (1032, 96, 144)\n      ‚úì CH4_anthro_fires: (1032, 96, 144)\n      ‚úì CH4_no_fires: (1032, 96, 144)\n      ‚úì CO2_sum: (1032, 96, 144)\n      ‚úì SO2_anthro_fires: (1032, 96, 144)\n      ‚úì SO2_no_fires: (1032, 96, 144)\n      ‚úì pr: (1032, 96, 144)\n      üîΩ Downsampling...\n         BC_anthro_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         BC_no_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         CH4_anthro_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         CH4_no_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         CO2_sum: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         SO2_anthro_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         SO2_no_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         pr: (1032, 96, 144) ‚Üí (1032, 9, 19)\n   üìÅ ssp245\n      ‚úì BC_anthro_fires: (1032, 96, 144)\n      ‚úì BC_no_fires: (1032, 96, 144)\n      ‚úì CH4_anthro_fires: (1032, 96, 144)\n      ‚úì CH4_no_fires: (1032, 96, 144)\n      ‚úì CO2_sum: (1032, 96, 144)\n      ‚úì SO2_anthro_fires: (1032, 96, 144)\n      ‚úì SO2_no_fires: (1032, 96, 144)\n      ‚úì pr: (1032, 96, 144)\n      üîΩ Downsampling...\n         BC_anthro_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         BC_no_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         CH4_anthro_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         CH4_no_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         CO2_sum: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         SO2_anthro_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         SO2_no_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         pr: (1032, 96, 144) ‚Üí (1032, 9, 19)\n   üìÅ ssp370\n      ‚úì BC_anthro_fires: (1032, 96, 144)\n      ‚úì BC_no_fires: (1032, 96, 144)\n      ‚úì CH4_anthro_fires: (1032, 96, 144)\n      ‚úì CH4_no_fires: (1032, 96, 144)\n      ‚úì CO2_sum: (1032, 96, 144)\n      ‚úì SO2_anthro_fires: (1032, 96, 144)\n      ‚úì SO2_no_fires: (1032, 96, 144)\n      ‚úì pr: (1032, 96, 144)\n      üîΩ Downsampling...\n         BC_anthro_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         BC_no_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         CH4_anthro_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         CH4_no_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         CO2_sum: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         SO2_anthro_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         SO2_no_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         pr: (1032, 96, 144) ‚Üí (1032, 9, 19)\n   üìÅ ssp585\n      ‚úì BC_anthro_fires: (1032, 96, 144)\n      ‚úì CH4_anthro_fires: (1032, 96, 144)\n      ‚úì CH4_no_fires: (1032, 96, 144)\n      ‚úì CO2_sum: (1032, 96, 144)\n      ‚úì SO2_anthro_fires: (1032, 96, 144)\n      ‚úì SO2_no_fires: (1032, 96, 144)\n      ‚úì pr: (1032, 96, 144)\n      üîΩ Downsampling...\n         BC_anthro_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         BC_no_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         CH4_anthro_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         CH4_no_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         CO2_sum: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         SO2_anthro_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         SO2_no_fires: (1032, 96, 144) ‚Üí (1032, 9, 19)\n         pr: (1032, 96, 144) ‚Üí (1032, 9, 19)\n   ‚úÖ Loaded 5 scenarios\nüîÑ Step 4/7: Creating sequences...\nüîÑ Creating sequences...\n   üì¶ historical (id=0)\n      ‚úì 1966 sequences\n   üì¶ ssp126 (id=1)\n      ‚úì 1018 sequences\n   üì¶ ssp245 (id=2)\n      ‚úì 1018 sequences\n   üì¶ ssp370 (id=3)\n      ‚úì 1018 sequences\n   üì¶ ssp585 (id=4)\n      ‚úì 1018 sequences\n   üß© Total: X=(6038, 12, 8, 9, 19), Y=(6038, 3, 1, 9, 19)\n   üìä Stratified split...\n   üì¶ Train:4226 Val:905 Test:907\nüß† Step 5/7: Creating STGNN model...\nüîß Initializing STGNN Predictor:\n   Input: 12 timesteps √ó 8 channels √ó 9√ó19\n   Hidden: 64, Blocks: 3\n   Output: 3 timesteps\nüìä Graph: 9√ó19 = 171 nodes, 1204 edges\n   Avg degree: 7.04\n‚úÖ STGNN initialized - Parameters: 103,528\n\nüöÇ Step 6/7: Training for 2 epochs...\n","output_type":"stream"},{"name":"stderr","text":"üåê BCC-CSM2-MR: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [01:48<00:00, 54.38s/it, train=0.002217, val=0.003915, best=0.003837, status=]           \n","output_type":"stream"},{"name":"stdout","text":"üíæ Step 7/7: Saving model...\n","output_type":"stream"},{"name":"stderr","text":"üåê Overall: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [18:27<00:00, 553.87s/it, success=2, skipped=0, failed=0]","output_type":"stream"},{"name":"stdout","text":"\n================================================================================\n‚úÖ STGNN Phase 4 Training Complete!\n================================================================================\nTotal: 2\n  ‚úÖ Successful: 2\n  ‚≠ê Skipped: 0\n  ‚ùå Failed: 0\nTotal time: 0.31 hours\n================================================================================\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## üìä Section 8: Results Analysis","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# üìä SECTION 8: RESULTS ANALYSIS\n# ============================================================================\n\nif summary:\n    print(\"\\n\" + \"=\"*80)\n    print(\"üìä STGNN PHASE 4 RESULTS SUMMARY\")\n    print(\"=\"*80)\n    print(f\"Model Type: {summary.get('model_type', 'STGNN')}\")\n    print(f\"Total institutions: {summary.get('total_institutions', 0)}\")\n    print(f\"  ‚úÖ Successful: {summary.get('successful', 0)}\")\n    print(f\"  ‚≠ê Skipped: {summary.get('skipped', 0)}\")\n    print(f\"  ‚ùå Failed: {summary.get('failed', 0)}\")\n    print(f\"Total time: {summary.get('total_time_hours', 0):.2f}h\")\n    print(f\"Scenarios: {summary.get('scenarios', [])}\")\n    \n    # Scenario performance\n    print(f\"\\nüåç Scenario Performance Across All Institutions:\")\n    print(\"=\"*80)\n    \n    scenario_perf = {s: [] for s in SCENARIOS.keys()}\n    \n    for result in summary.get('results', []):\n        if result.get('success') and not result.get('skipped'):\n            inst_results = result.get('results', {})\n            final_losses = inst_results.get('final_scenario_losses', {})\n            \n            for scenario, loss in final_losses.items():\n                if scenario in scenario_perf:\n                    scenario_perf[scenario].append(loss)\n    \n    for scenario, losses in scenario_perf.items():\n        if losses:\n            avg = np.mean(losses)\n            std = np.std(losses)\n            min_loss = np.min(losses)\n            max_loss = np.max(losses)\n            print(f\"   {scenario.upper():12s}: Avg={avg:.6f}¬±{std:.6f} | Min={min_loss:.6f} | Max={max_loss:.6f}\")\n        else:\n            print(f\"   {scenario.upper():12s}: No data\")\n    \n    print(\"=\"*80)\n    \n    # Visualization\n    if scenario_perf and any(scenario_perf.values()):\n        fig, ax = plt.subplots(figsize=(12, 6))\n        \n        scenarios_with_data = [s for s, losses in scenario_perf.items() if losses]\n        avg_losses = [np.mean(scenario_perf[s]) for s in scenarios_with_data]\n        std_losses = [np.std(scenario_perf[s]) for s in scenarios_with_data]\n        \n        x = np.arange(len(scenarios_with_data))\n        ax.bar(x, avg_losses, yerr=std_losses, capsize=5, alpha=0.7, color='teal')\n        ax.set_xlabel('Scenario', fontsize=12)\n        ax.set_ylabel('Average Loss', fontsize=12)\n        ax.set_title('STGNN Performance Across Climate Scenarios', fontsize=14, fontweight='bold')\n        ax.set_xticks(x)\n        ax.set_xticklabels([s.upper() for s in scenarios_with_data], rotation=45)\n        ax.grid(True, alpha=0.3)\n        \n        plt.tight_layout()\n        plt.savefig(os.path.join(OUTPUT_DIR, \"plots\", \"stgnn_scenario_performance.png\"), \n                   dpi=300, bbox_inches='tight')\n        plt.show()\n        \n        print(f\"\\nüìä Plot saved to: {OUTPUT_DIR}/plots/stgnn_scenario_performance.png\")\n\nprint(f\"\\n‚úÖ Results saved to: {OUTPUT_DIR}\")\nprint(\"=\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T11:50:49.301163Z","iopub.execute_input":"2025-10-09T11:50:49.301706Z","iopub.status.idle":"2025-10-09T11:50:50.042297Z","shell.execute_reply.started":"2025-10-09T11:50:49.301688Z","shell.execute_reply":"2025-10-09T11:50:50.041399Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nüìä STGNN PHASE 4 RESULTS SUMMARY\n================================================================================\nModel Type: STGNN\nTotal institutions: 2\n  ‚úÖ Successful: 2\n  ‚≠ê Skipped: 0\n  ‚ùå Failed: 0\nTotal time: 0.31h\nScenarios: ['historical', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n\nüåç Scenario Performance Across All Institutions:\n================================================================================\n   HISTORICAL  : Avg=0.005502¬±0.001938 | Min=0.003564 | Max=0.007441\n   SSP126      : Avg=0.005725¬±0.001930 | Min=0.003795 | Max=0.007655\n   SSP245      : Avg=0.006083¬±0.002559 | Min=0.003524 | Max=0.008642\n   SSP370      : Avg=0.007052¬±0.002387 | Min=0.004665 | Max=0.009439\n   SSP585      : Avg=0.007740¬±0.003385 | Min=0.004355 | Max=0.011125\n================================================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"\nüìä Plot saved to: stgnn_phase4_multiscenario_results/plots/stgnn_scenario_performance.png\n\n‚úÖ Results saved to: stgnn_phase4_multiscenario_results\n================================================================================\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"---\n\n## üéâ Complete!\n\n### üåü What's Different: STGNN vs GNN-GRU\n\n| Component | **Previous (GNN-GRU)** | **Now (STGNN)** |\n|-----------|----------------------|----------------|\n| **Architecture** | Separate spatial (GNN) + temporal (GRU) | Unified spatio-temporal blocks |\n| **Temporal** | GRU (sequential) | Temporal convolution (parallel) |\n| **Processing** | Sequential over time | Processes all timesteps together |\n| **Efficiency** | Moderate (GRU overhead) | Higher (parallel processing) |\n| **Parameters** | ~1-1.5M | ~800K-1.2M |\n| **Training Speed** | Slower (sequential) | Faster (parallel) |\n| **Climate Data** | Good | Better (captures ST patterns) |\n\n### üî¨ STGNN Architecture:\n```\nInput (12√ó8√ó9√ó19)\n    ‚Üì\n[Graph: 8-neighbor connectivity]\n    ‚Üì\n[Input Embed: 8 ‚Üí 64]\n[+ Positional Encoding]\n    ‚Üì\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë   STGNN Block √ó 3                 ‚ïë\n‚ïë   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚ïë\n‚ïë   ‚îÇ Temporal Conv (1D)      ‚îÇ    ‚ïë\n‚ïë   ‚îÇ ‚Üì                       ‚îÇ    ‚ïë\n‚ïë   ‚îÇ Graph Conv (Spatial)    ‚îÇ    ‚ïë\n‚ïë   ‚îÇ ‚Üì                       ‚îÇ    ‚ïë\n‚ïë   ‚îÇ Feed-Forward Network    ‚îÇ    ‚ïë\n‚ïë   ‚îÇ ‚Üì                       ‚îÇ    ‚ïë\n‚ïë   ‚îÇ Layer Norm + Residual   ‚îÇ    ‚ïë\n‚ïë   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n    ‚Üì\n[Temporal Projection: 12 ‚Üí 3]\n    ‚Üì\n[Output Projection: 64 ‚Üí 1]\n[+ Softplus]\n    ‚Üì\nOutput (3√ó1√ó9√ó19)\n```\n\n### üéØ Key Advantages of STGNN:\n\n#### **1. Unified Processing**\n- Processes spatial and temporal together\n- No separation between spatial and temporal\n- More natural for climate data\n\n#### **2. Parallel Temporal Processing**\n```python\n# GNN-GRU (Sequential)\nfor t in timesteps:\n    hidden = gru_cell(x[t], hidden)  # One at a time\n\n# STGNN (Parallel)\nx_all_time = temporal_conv(x)  # All at once!\n```\n\n#### **3. Causal Temporal Convolutions**\n- Only looks at past (causal padding)\n- Respects temporal ordering\n- Prevents information leakage\n\n#### **4. Better for Climate**\n- Climate has strong spatio-temporal correlations\n- STGNN captures these naturally\n- No artificial separation\n\n### üìä Expected Performance:\n\n| Metric | STGNN Expected | Previous GNN-GRU |\n|--------|---------------|------------------|\n| **Training Speed** | **~30-40 min/epoch** | ~45-60 min/epoch |\n| **Memory** | **~3-4 GB** | ~4-5 GB |\n| **Parameters** | **~800K-1.2M** | ~1-1.5M |\n| **MAE** | **0.0003-0.0008** | 0.0004-0.0010 |\n| **R¬≤** | **0.7-0.92** | 0.65-0.88 |\n\n### üîß Technical Details:\n\n#### **Temporal Convolution**\n```python\n# 1D convolution over time\n# Kernel size 3 = looks at [t-2, t-1, t]\n# Causal padding = no future information\n```\n\n#### **Spatio-Temporal Block**\n```python\n1. Temporal Conv ‚Üí captures time patterns\n2. Graph Conv ‚Üí captures spatial patterns  \n3. FFN ‚Üí non-linear transformations\n4. Layer Norm + Residual ‚Üí stable training\n```\n\n#### **Temporal Projection**\n```python\n# Projects 12 input timesteps ‚Üí 3 output timesteps\n# Learnable Conv1d(12, 3)\n# More flexible than taking last 3\n```\n\n### üìÅ Output Files:\n- **Models**: `stgnn_phase4_multiscenario_results/checkpoints/{inst}_stgnn_multiscenario_best.pt`\n- **Logs**: `stgnn_phase4_multiscenario_results/logs/{inst}_stgnn_phase4_results.json`\n- **Summary**: `stgnn_phase4_multiscenario_results/logs/stgnn_phase4_training_summary.json`\n- **Plots**: `stgnn_phase4_multiscenario_results/plots/stgnn_scenario_performance.png`\n\n### üöÄ Ready to Compare!\n\nNow you have:\n1. ‚úÖ ConvLSTM (CNN + LSTM)\n2. ‚úÖ ClimAx (Vision Transformer)\n3. ‚úÖ **STGNN** (Unified spatio-temporal graph)\n\n**Perfect for comprehensive comparison!**","metadata":{}}]}