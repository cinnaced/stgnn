{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13303078,"sourceType":"datasetVersion","datasetId":8432230}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 🌐 Spatio-Temporal GNN Phase 4 - Multi-Scenario Climate Prediction\n\n**Complete STGNN notebook with multi-scenario training across 18 CMIP6 institutions**\n\n---\n\n## 📋 Features\n- ✅ **Spatio-Temporal Graph Neural Network** (unified spatial-temporal modeling)\n- ✅ **Temporal Graph Convolutions** for time-aware processing\n- ✅ **Multi-Scenario Training** (historical + SSP126/245/370/585)\n- ✅ **Stratified Splitting** (all scenarios in train/val/test)\n- ✅ **8-neighbor Grid Connectivity**\n- ✅ **Scenario Embeddings** as 8th input channel\n- ✅ Same dataset as ConvLSTM (7 vars + scenario → precipitation)\n- ✅ Memory-efficient for 6GB GPU\n- ✅ Multi-institution support\n\n## 🎯 STGNN Architecture\n- **Spatial**: Graph Convolution (8-neighbor)\n- **Temporal**: Temporal Convolution (causal)\n- **Combined**: Spatio-Temporal Blocks\n- **Input**: 12 timesteps × 8 channels × 9×19 spatial\n- **Output**: 3 timesteps × 1 variable × 9×19 spatial\n\n## 🔬 Why STGNN?\n- **Unified Processing**: Spatial + temporal in one operation\n- **Better Efficiency**: No separate GRU overhead\n- **Parallel Processing**: Temporal convolutions are parallelizable\n- **Climate-Appropriate**: Captures spatio-temporal patterns naturally\n\n---","metadata":{}},{"cell_type":"markdown","source":"## 📦 Section 1: Install & Import Dependencies","metadata":{}},{"cell_type":"code","source":"!pip install torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv \\\n  -f https://data.pyg.org/whl/torch-2.6.0+cu124.html\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T11:31:58.435092Z","iopub.execute_input":"2025-10-09T11:31:58.435255Z","iopub.status.idle":"2025-10-09T11:32:07.782706Z","shell.execute_reply.started":"2025-10-09T11:31:58.435239Z","shell.execute_reply":"2025-10-09T11:32:07.781873Z"}},"outputs":[{"name":"stdout","text":"Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\nCollecting torch-geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting torch-scatter\n  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_scatter-2.1.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torch-sparse\n  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_sparse-0.6.18%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (5.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hCollecting torch-cluster\n  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_cluster-1.6.3%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting torch-spline-conv\n  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_spline_conv-1.2.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (1.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.12.15)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.9.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (7.1.0)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.0.9)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.5)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.15.3)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.6.4)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.8.3)\nRequirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch-geometric) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch-geometric) (2024.2.0)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-geometric, torch-cluster\nSuccessfully installed torch-cluster-1.6.3+pt26cu124 torch-geometric-2.6.1 torch-scatter-2.1.2+pt26cu124 torch-sparse-0.6.18+pt26cu124 torch-spline-conv-1.2.2+pt26cu124\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from torch_geometric.nn import GCNConv\nprint(\"✅ PyTorch Geometric is working!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T11:32:07.783670Z","iopub.execute_input":"2025-10-09T11:32:07.783868Z","iopub.status.idle":"2025-10-09T11:32:20.007041Z","shell.execute_reply.started":"2025-10-09T11:32:07.783848Z","shell.execute_reply":"2025-10-09T11:32:20.006327Z"}},"outputs":[{"name":"stdout","text":"✅ PyTorch Geometric is working!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ============================================================================\n# 📦 SECTION 1: INSTALL & IMPORT DEPENDENCIES\n# ============================================================================\n\nimport os\nimport sys\nimport glob\nimport time\nimport json\nimport warnings\nimport gc\nfrom datetime import datetime\nfrom typing import Dict, List, Tuple, Optional\n\nimport numpy as np\nimport pandas as pd\nimport xarray as xr\nfrom scipy.ndimage import zoom\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch_geometric.nn import GCNConv\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\n\nwarnings.filterwarnings('ignore')\n\n# GPU setup\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"🚀 Using device: {device}\")\nif torch.cuda.is_available():\n    print(f\"📊 GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"💾 GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\nelse:\n    print(\"⚠️ WARNING: No GPU detected - training will be VERY slow!\")\n\nsys.stdout.flush()\nprint(\"✅ All imports successful!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T11:32:20.008948Z","iopub.execute_input":"2025-10-09T11:32:20.009362Z","iopub.status.idle":"2025-10-09T11:32:21.402669Z","shell.execute_reply.started":"2025-10-09T11:32:20.009344Z","shell.execute_reply":"2025-10-09T11:32:21.401904Z"}},"outputs":[{"name":"stdout","text":"🚀 Using device: cuda\n📊 GPU: Tesla P100-PCIE-16GB\n💾 GPU Memory: 15.9 GB\n✅ All imports successful!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## ⚙️ Section 2: Configuration","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# ⚙️ SECTION 2: CONFIGURATION\n# ============================================================================\n\n# Paths\nINPUT_DATA_DIR = \"/kaggle/input/climate-dataset/Datasets/inputs/input4mips\"\nOUTPUT_DATA_DIR = \"/kaggle/input/climate-dataset/Datasets/outputs/CMIP6\"\nOUTPUT_DIR = \"stgnn_phase4_multiscenario_results\"\n\n# Training settings\nSMOKE_TEST = True              # True = 2 institutions, 2 epochs for testing\nRESUME_IF_MODEL_EXISTS = True  # Skip already trained models\nSKIP_TRAINING = False          # Set True to only load results\n\n# Memory settings\nTARGET_SPATIAL_H = 9\nTARGET_SPATIAL_W = 19\nBATCH_SIZE = 1\nEPOCHS = 2 if SMOKE_TEST else 15\n\n# Model settings (STGNN)\nHIDDEN_DIM = 64\nSTGNN_BLOCKS = 3              # Number of spatio-temporal blocks\nTEMPORAL_KERNEL_SIZE = 3       # Temporal convolution kernel\nSPATIAL_KERNEL_SIZE = 2        # Graph conv layers per block\nDROPOUT = 0.2\n\n# All 18 institutions\nALL_INSTITUTIONS = [\n    \"AWI-CM-1-1-MR\", \"BCC-CSM2-MR\", \"CAS-ESM2-0\", \"CESM2\",\n    \"CESM2-WACCM\", \"CMCC-CM2-SR5\", \"CMCC-ESM2\", \"CNRM-CM6-1-HR\",\n    \"EC-Earth3\", \"EC-Earth3-Veg\", \"EC-Earth3-Veg-LR\", \"FGOALS-f3-L\",\n    \"GFDL-ESM4\", \"INM-CM4-8\", \"INM-CM5-0\", \"MPI-ESM1-2-HR\",\n    \"MRI-ESM2-0\", \"TaiESM1\"\n]\n\n# Scenarios with numeric IDs\nSCENARIOS = {\n    'historical': 0,\n    'ssp126': 1,\n    'ssp245': 2,\n    'ssp370': 3,\n    'ssp585': 4\n}\n\n# Input variables (7 climate forcing variables)\nINPUT_VARIABLES = [\n    'BC_anthro_fires', 'BC_no_fires',\n    'CH4_anthro_fires', 'CH4_no_fires',\n    'CO2_sum',\n    'SO2_anthro_fires', 'SO2_no_fires'\n]\n\n# Total input channels: 7 variables + 1 scenario channel = 8\nNUM_INPUT_CHANNELS = 8\n\nOUTPUT_VARIABLE = 'pr'\n\n# Create directories\nos.makedirs(OUTPUT_DIR, exist_ok=True)\nos.makedirs(os.path.join(OUTPUT_DIR, \"checkpoints\"), exist_ok=True)\nos.makedirs(os.path.join(OUTPUT_DIR, \"logs\"), exist_ok=True)\nos.makedirs(os.path.join(OUTPUT_DIR, \"plots\"), exist_ok=True)\n\nprint(\"✅ Configuration loaded\")\nprint(f\"   📁 Input: {INPUT_DATA_DIR}\")\nprint(f\"   📁 Output: {OUTPUT_DATA_DIR}\")\nprint(f\"   💾 Results: {OUTPUT_DIR}\")\nprint(f\"   🗺️  Spatial: {TARGET_SPATIAL_H}×{TARGET_SPATIAL_W}\")\nprint(f\"   🏢 Institutions: {len(ALL_INSTITUTIONS)}\")\nprint(f\"   🌍 Scenarios: {list(SCENARIOS.keys())}\")\nprint(f\"   📊 Input channels: {NUM_INPUT_CHANNELS} (7 vars + scenario)\")\nprint(f\"   🔧 STGNN blocks: {STGNN_BLOCKS}\")\nprint(f\"   ⚙️  Smoke test: {SMOKE_TEST}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T11:32:21.403972Z","iopub.execute_input":"2025-10-09T11:32:21.404462Z","iopub.status.idle":"2025-10-09T11:32:21.413057Z","shell.execute_reply.started":"2025-10-09T11:32:21.404433Z","shell.execute_reply":"2025-10-09T11:32:21.412370Z"}},"outputs":[{"name":"stdout","text":"✅ Configuration loaded\n   📁 Input: /kaggle/input/climate-dataset/Datasets/inputs/input4mips\n   📁 Output: /kaggle/input/climate-dataset/Datasets/outputs/CMIP6\n   💾 Results: stgnn_phase4_multiscenario_results\n   🗺️  Spatial: 9×19\n   🏢 Institutions: 18\n   🌍 Scenarios: ['historical', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n   📊 Input channels: 8 (7 vars + scenario)\n   🔧 STGNN blocks: 3\n   ⚙️  Smoke test: True\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## 🗺️ Section 3: Graph Construction Utilities","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# 🗺️ SECTION 3: GRAPH CONSTRUCTION\n# ============================================================================\n\ndef build_grid_graph_8neighbor(height: int, width: int) -> torch.Tensor:\n    \"\"\"Build 8-neighbor connectivity graph for grid.\"\"\"\n    edges = []\n    \n    def pos_to_idx(i, j):\n        return i * width + j\n    \n    # 8 directions: N, S, E, W, NE, NW, SE, SW\n    directions = [\n        (-1, 0), (1, 0), (0, -1), (0, 1),\n        (-1, -1), (-1, 1), (1, -1), (1, 1)\n    ]\n    \n    for i in range(height):\n        for j in range(width):\n            src_idx = pos_to_idx(i, j)\n            for di, dj in directions:\n                ni, nj = i + di, j + dj\n                if 0 <= ni < height and 0 <= nj < width:\n                    dst_idx = pos_to_idx(ni, nj)\n                    edges.append([src_idx, dst_idx])\n    \n    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n    print(f\"📊 Graph: {height}×{width} = {height*width} nodes, {edge_index.shape[1]} edges\")\n    print(f\"   Avg degree: {edge_index.shape[1] / (height*width):.2f}\")\n    return edge_index\n\n\ndef add_self_loops(edge_index: torch.Tensor, num_nodes: int) -> torch.Tensor:\n    \"\"\"Add self-loops to graph.\"\"\"\n    self_loops = torch.stack([torch.arange(num_nodes), torch.arange(num_nodes)], dim=0)\n    return torch.cat([edge_index, self_loops], dim=1)\n\n\ndef get_positional_encoding(height: int, width: int, embed_dim: int) -> torch.Tensor:\n    \"\"\"Generate 2D positional encoding.\"\"\"\n    y_coords = torch.linspace(0, 1, height)\n    x_coords = torch.linspace(0, 1, width)\n    yy, xx = torch.meshgrid(y_coords, x_coords, indexing='ij')\n    coords = torch.stack([yy.flatten(), xx.flatten()], dim=1)\n    \n    pos_encoding = torch.zeros(height * width, embed_dim)\n    for i in range(embed_dim // 2):\n        freq = 1.0 / (10000 ** (2 * i / embed_dim))\n        pos_encoding[:, 2*i] = torch.sin(coords[:, 0] * freq)\n        pos_encoding[:, 2*i + 1] = torch.cos(coords[:, 1] * freq)\n    \n    return pos_encoding\n\n\nprint(\"✅ Graph utilities loaded\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T11:32:21.413962Z","iopub.execute_input":"2025-10-09T11:32:21.414342Z","iopub.status.idle":"2025-10-09T11:32:21.444623Z","shell.execute_reply.started":"2025-10-09T11:32:21.414317Z","shell.execute_reply":"2025-10-09T11:32:21.443731Z"}},"outputs":[{"name":"stdout","text":"✅ Graph utilities loaded\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## 📊 Section 4: Multi-Scenario Data Loader\n\n*Same as previous - unchanged*","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# 📊 SECTION 4: MULTI-SCENARIO DATA LOADER (SAME AS BEFORE)\n# ============================================================================\n\nclass ClimateDatasetWithScenario(Dataset):\n    \"\"\"PyTorch dataset with scenario information.\"\"\"\n    \n    def __init__(self, X: np.ndarray, y: np.ndarray, scenarios: np.ndarray):\n        self.X = torch.from_numpy(X.astype(np.float32))\n        self.y = torch.from_numpy(y.astype(np.float32))\n        self.scenarios = torch.from_numpy(scenarios.astype(np.float32))\n    \n    def __len__(self):\n        return self.X.shape[0]\n    \n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx], self.scenarios[idx]\n\n\nclass MultiScenarioDataLoader:\n    \"\"\"Multi-Scenario Data Loader for STGNN.\"\"\"\n    \n    def __init__(self, target_h: int = 9, target_w: int = 19):\n        self.input_base = INPUT_DATA_DIR\n        self.output_base = OUTPUT_DATA_DIR\n        self.target_h = target_h\n        self.target_w = target_w\n        self.scalers = {}\n        self.scenarios = SCENARIOS\n        self.input_variables = INPUT_VARIABLES\n        \n        self.variable_dirs = {\n            'BC_anthro_fires': 'BC_sum', 'BC_no_fires': 'BC_sum',\n            'CH4_anthro_fires': 'CH4_sum', 'CH4_no_fires': 'CH4_sum',\n            'CO2_sum': 'CO2_sum',\n            'SO2_anthro_fires': 'SO2_sum', 'SO2_no_fires': 'SO2_sum'\n        }\n        self.output_variable = OUTPUT_VARIABLE\n        print(f\"📊 DataLoader initialized: {target_h}×{target_w}\")\n    \n    def _matches_variable_pattern(self, filename: str, variable: str) -> bool:\n        \"\"\"Pattern matching for filenames.\"\"\"\n        f = filename.lower()\n        patterns = {\n            'BC_anthro_fires': (['bc', 'anthro'], ['fire']),\n            'BC_no_fires': (['bc', 'no'], ['fire']),\n            'CH4_anthro_fires': (['ch4', 'anthro'], ['fire']),\n            'CH4_no_fires': (['ch4', 'no'], ['fire']),\n            'CO2_sum': (['co2'], []),\n            'SO2_anthro_fires': (['so2', 'anthro'], ['fire']),\n            'SO2_no_fires': (['so2', 'no'], ['fire'])\n        }\n        \n        if variable in patterns:\n            req, opt = patterns[variable]\n            has_req = all(p in f for p in req)\n            if 'no' in req:\n                has_req = has_req and 'anthro' not in f\n            if opt:\n                return has_req and any(p in f for p in opt)\n            return has_req\n        return False\n    \n    def _is_file_readable(self, file_path: str) -> bool:\n        \"\"\"Check if file can be opened.\"\"\"\n        try:\n            if not os.path.exists(file_path) or os.path.getsize(file_path) < 1000:\n                return False\n            with xr.open_dataset(file_path, decode_times=False) as ds:\n                _ = list(ds.data_vars.keys())\n            return True\n        except:\n            return False\n    \n    def discover_files_multi_scenario(self, institution: str):\n        \"\"\"Discover files for all scenarios.\"\"\"\n        print(f\"🔍 Discovering files for {institution}...\")\n        all_scenario_files = {}\n        \n        for scenario in self.scenarios.keys():\n            print(f\"   📁 {scenario}\")\n            results_inputs = {}\n            results_outputs = {}\n            \n            # Input files\n            for var in self.input_variables:\n                folder = self.variable_dirs.get(var, var)\n                path = os.path.join(self.input_base, scenario, folder)\n                \n                if not os.path.exists(path):\n                    continue\n                \n                found = []\n                for root, dirs, files in os.walk(path):\n                    for fname in files:\n                        if fname.endswith('.nc') and self._matches_variable_pattern(fname, var):\n                            fpath = os.path.join(root, fname)\n                            if self._is_file_readable(fpath):\n                                found.append(fpath)\n                \n                if found:\n                    results_inputs[var] = found\n                    print(f\"      ✓ {var}: {len(found)} files\")\n            \n            # Output files\n            out_path = os.path.join(self.output_base, institution, scenario, self.output_variable)\n            if os.path.exists(out_path):\n                out_files = []\n                for root, dirs, files in os.walk(out_path):\n                    for fname in files:\n                        if fname.endswith('.nc'):\n                            fpath = os.path.join(root, fname)\n                            if self._is_file_readable(fpath):\n                                out_files.append(fpath)\n                \n                if out_files:\n                    results_outputs[self.output_variable] = out_files\n                    print(f\"      ✓ {self.output_variable}: {len(out_files)} files\")\n            \n            all_scenario_files[scenario] = {\"inputs\": results_inputs, \"outputs\": results_outputs}\n        \n        return all_scenario_files\n    \n    def downsample_spatial(self, arr, target_h, target_w):\n        \"\"\"Downsample using scipy.ndimage.zoom.\"\"\"\n        if arr.shape[1] == target_h and arr.shape[2] == target_w:\n            return arr\n        T, H, W = arr.shape\n        downsampled = zoom(arr, [1.0, target_h/H, target_w/W], order=1, mode='nearest')\n        return downsampled[:, :target_h, :target_w]\n    \n    def _load_netcdf_list(self, paths, var_hint=None):\n        \"\"\"Load and concatenate NetCDF files.\"\"\"\n        arrays = []\n        for p in sorted(paths):\n            try:\n                ds = xr.open_dataset(p, decode_times=False)\n                dvars = list(ds.data_vars.keys())\n                if not dvars:\n                    ds.close()\n                    continue\n                var = var_hint if (var_hint and var_hint in dvars) else dvars[0]\n                arr = ds[var].values\n                ds.close()\n                if arr.ndim == 2:\n                    arr = np.expand_dims(arr, 0)\n                elif arr.ndim > 3:\n                    arr = arr.reshape(-1, arr.shape[-2], arr.shape[-1])\n                arrays.append(np.nan_to_num(arr, 0.0, 0.0, 0.0))\n            except Exception:\n                continue\n        \n        if not arrays:\n            return np.zeros((0, 0, 0), dtype=float)\n        \n        try:\n            return np.concatenate(arrays, axis=0)\n        except:\n            mh = max(a.shape[1] for a in arrays)\n            mw = max(a.shape[2] for a in arrays)\n            padded = [np.pad(a, ((0,0), (0,mh-a.shape[1]), (0,mw-a.shape[2])), 'edge') for a in arrays]\n            return np.concatenate(padded, axis=0)\n    \n    def align_temporal_dimensions(self, var_data):\n        \"\"\"Align temporal dimensions.\"\"\"\n        if not var_data:\n            return var_data\n        times = {v: a.shape[0] for v, a in var_data.items()}\n        mt = min(times.values())\n        if mt != max(times.values()):\n            print(f\"      ⚠️ Aligning to {mt} timesteps\")\n            return {v: a[:mt] for v, a in var_data.items()}\n        return var_data\n    \n    def load_all_scenarios(self, all_files):\n        \"\"\"Load all scenario data.\"\"\"\n        print(\"📊 Loading scenarios...\")\n        all_data = {}\n        \n        for scenario, files in all_files.items():\n            print(f\"   📁 {scenario}\")\n            var_data = {}\n            \n            for var, paths in files.get(\"inputs\", {}).items():\n                if paths:\n                    arr = self._load_netcdf_list(paths)\n                    if arr.size > 0:\n                        var_data[var] = arr\n                        print(f\"      ✓ {var}: {arr.shape}\")\n            \n            for var, paths in files.get(\"outputs\", {}).items():\n                if paths:\n                    arr = self._load_netcdf_list(paths)\n                    if arr.size > 0:\n                        var_data[var] = arr\n                        print(f\"      ✓ {var}: {arr.shape}\")\n            \n            if var_data:\n                var_data = self.align_temporal_dimensions(var_data)\n                print(f\"      🔽 Downsampling...\")\n                down_data = {}\n                for v, a in var_data.items():\n                    d = self.downsample_spatial(a, self.target_h, self.target_w)\n                    down_data[v] = d\n                    print(f\"         {v}: {a.shape} → {d.shape}\")\n                all_data[scenario] = down_data\n        \n        print(f\"   ✅ Loaded {len(all_data)} scenarios\")\n        return all_data\n    \n    def normalize_data(self, arr, var_name, fit=True):\n        \"\"\"Normalize data.\"\"\"\n        arr = np.nan_to_num(arr, 0.0, 0.0, 0.0)\n        flat = arr.reshape(-1, 1)\n        \n        if fit or var_name not in self.scalers:\n            scaler = MinMaxScaler()\n            try:\n                scaler.fit(flat)\n            except:\n                scaler.min_, scaler.scale_ = np.min(flat), 1.0\n            self.scalers[var_name] = scaler\n        else:\n            scaler = self.scalers[var_name]\n        \n        return np.nan_to_num(scaler.transform(flat).reshape(arr.shape), 0.0, 0.0, 0.0)\n    \n    def create_multi_scenario_sequences(self, all_data, seq_in=12, seq_out=3, stride=1, \n                                       train_ratio=0.7, val_ratio=0.15, batch_size=1):\n        \"\"\"Create sequences with stratified splitting.\"\"\"\n        print(\"🔄 Creating sequences...\")\n        X_seqs, Y_seqs, sc_ids = [], [], []\n        \n        for scenario, var_data in all_data.items():\n            if not var_data:\n                continue\n            \n            sc_id = self.scenarios[scenario]\n            print(f\"   📦 {scenario} (id={sc_id})\")\n            \n            missing = [v for v in self.input_variables if v not in var_data]\n            if missing or self.output_variable not in var_data:\n                print(f\"      ⚠️ Skipping - missing data\")\n                continue\n            \n            # Normalize\n            norm = {v: self.normalize_data(var_data[v], v, True) for v in self.input_variables if v in var_data}\n            norm[self.output_variable] = self.normalize_data(var_data[self.output_variable], \n                                                             self.output_variable, True)\n            \n            # Stack\n            X_sc = np.stack([norm[v] for v in self.input_variables if v in norm], axis=1)\n            Y_sc = norm[self.output_variable]\n            \n            T = X_sc.shape[0]\n            n_samp = T - seq_in - seq_out + 1\n            \n            if n_samp <= 0:\n                print(f\"      ⚠️ Not enough timesteps\")\n                continue\n            \n            for start in range(0, n_samp, stride):\n                X_seqs.append(X_sc[start:start+seq_in])\n                Y_seqs.append(Y_sc[start+seq_in:start+seq_in+seq_out])\n                sc_ids.append(sc_id)\n            \n            print(f\"      ✓ {n_samp} sequences\")\n        \n        if not X_seqs:\n            raise RuntimeError(\"❌ No sequences!\")\n        \n        X_all = np.stack(X_seqs, 0)\n        Y_all = np.stack(Y_seqs, 0)\n        sc_all = np.array(sc_ids)\n        \n        # Add scenario channel\n        N, T, C, H, W = X_all.shape\n        sc_ch = np.repeat(sc_all[:, None, None, None, None], T*H*W, 1).reshape(N, T, 1, H, W)\n        X_all = np.concatenate([X_all, sc_ch], 2)\n        Y_all = np.expand_dims(Y_all, 2)\n        \n        print(f\"   🧩 Total: X={X_all.shape}, Y={Y_all.shape}\")\n        \n        # Stratified split\n        print(\"   📊 Stratified split...\")\n        X_tr, X_tmp, y_tr, y_tmp, sc_tr, sc_tmp = train_test_split(\n            X_all, Y_all, sc_all, test_size=(1-train_ratio), stratify=sc_all, random_state=42\n        )\n        vt_ratio = val_ratio / (1 - train_ratio)\n        X_val, X_te, y_val, y_te, sc_val, sc_te = train_test_split(\n            X_tmp, y_tmp, sc_tmp, test_size=(1-vt_ratio), stratify=sc_tmp, random_state=42\n        )\n        \n        splits = {\n            \"train\": {\"input\": X_tr, \"target\": y_tr, \"scenarios\": sc_tr},\n            \"validation\": {\"input\": X_val, \"target\": y_val, \"scenarios\": sc_val},\n            \"test\": {\"input\": X_te, \"target\": y_te, \"scenarios\": sc_te}\n        }\n        \n        loaders = {\n            \"train\": DataLoader(ClimateDatasetWithScenario(X_tr, y_tr, sc_tr), batch_size, True, \n                               pin_memory=False, num_workers=0),\n            \"validation\": DataLoader(ClimateDatasetWithScenario(X_val, y_val, sc_val), batch_size, False,\n                                    pin_memory=False, num_workers=0),\n            \"test\": DataLoader(ClimateDatasetWithScenario(X_te, y_te, sc_te), batch_size, False,\n                              pin_memory=False, num_workers=0)\n        }\n        \n        print(f\"   📦 Train:{len(X_tr)} Val:{len(X_val)} Test:{len(X_te)}\")\n        return splits, loaders\n\n\nprint(\"✅ Multi-scenario data loader defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T11:32:21.445581Z","iopub.execute_input":"2025-10-09T11:32:21.446208Z","iopub.status.idle":"2025-10-09T11:32:21.480627Z","shell.execute_reply.started":"2025-10-09T11:32:21.446189Z","shell.execute_reply":"2025-10-09T11:32:21.479791Z"}},"outputs":[{"name":"stdout","text":"✅ Multi-scenario data loader defined\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## 🧠 Section 5: Spatio-Temporal GNN Architecture\n\n**Key Innovation: Unified spatio-temporal processing**","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# 🧠 SECTION 5: SPATIO-TEMPORAL GNN ARCHITECTURE\n# ============================================================================\n\nclass TemporalConv(nn.Module):\n    \"\"\"\n    Temporal Convolution with causal padding.\n    Processes time dimension with 1D convolution.\n    \"\"\"\n    \n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int = 3):\n        super().__init__()\n        self.kernel_size = kernel_size\n        # Causal padding: only look at past\n        self.padding = (kernel_size - 1)\n        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, padding=self.padding)\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Args:\n            x: [batch, nodes, time, features]\n        Returns:\n            x: [batch, nodes, time, features]\n        \"\"\"\n        batch, nodes, time, features = x.shape\n        \n        # Reshape for 1D conv: [batch * nodes, features, time]\n        x = x.reshape(batch * nodes, time, features).permute(0, 2, 1)\n        \n        # Apply temporal convolution\n        x = self.conv(x)\n        \n        # Remove future timesteps (causal)\n        if self.padding > 0:\n            x = x[:, :, :-self.padding]\n        \n        # Reshape back: [batch, nodes, time, features]\n        x = x.permute(0, 2, 1).reshape(batch, nodes, time, features)\n        \n        return x\n\n\nclass SpatialGraphConv(nn.Module):\n    \"\"\"\n    Spatial Graph Convolution.\n    Processes spatial dimension with graph convolution.\n    \"\"\"\n    \n    def __init__(self, in_channels: int, out_channels: int):\n        super().__init__()\n        self.conv = GCNConv(in_channels, out_channels)\n        self.bn = nn.BatchNorm1d(out_channels)\n    \n    def forward(self, x: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Args:\n            x: [batch * time, nodes, features]\n            edge_index: [2, num_edges]\n        Returns:\n            x: [batch * time, nodes, features]\n        \"\"\"\n        batch_time, nodes, features = x.shape\n        \n        # Reshape for graph conv: [batch_time * nodes, features]\n        x = x.reshape(batch_time * nodes, features)\n        \n        # Apply graph convolution\n        x = self.conv(x, edge_index)\n        x = self.bn(x)\n        x = F.relu(x)\n        \n        # Reshape back: [batch_time, nodes, features]\n        x = x.reshape(batch_time, nodes, features)\n        \n        return x\n\n\nclass STGNNBlock(nn.Module):\n    \"\"\"\n    Spatio-Temporal Graph Neural Network Block.\n    \n    Combines:\n    1. Temporal Convolution (captures temporal patterns)\n    2. Spatial Graph Convolution (captures spatial patterns)\n    3. Residual connection + Layer Norm\n    \"\"\"\n    \n    def __init__(self, hidden_dim: int, temporal_kernel: int = 3, dropout: float = 0.2):\n        super().__init__()\n        \n        self.temporal_conv = TemporalConv(hidden_dim, hidden_dim, temporal_kernel)\n        self.spatial_conv = SpatialGraphConv(hidden_dim, hidden_dim)\n        \n        self.layer_norm1 = nn.LayerNorm(hidden_dim)\n        self.layer_norm2 = nn.LayerNorm(hidden_dim)\n        \n        self.dropout = nn.Dropout(dropout)\n        \n        # FFN\n        self.ffn = nn.Sequential(\n            nn.Linear(hidden_dim, hidden_dim * 2),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim * 2, hidden_dim),\n            nn.Dropout(dropout)\n        )\n        self.layer_norm3 = nn.LayerNorm(hidden_dim)\n    \n    def forward(self, x: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Args:\n            x: [batch, nodes, time, features]\n            edge_index: [2, num_edges]\n        Returns:\n            x: [batch, nodes, time, features]\n        \"\"\"\n        batch, nodes, time, features = x.shape\n        \n        # 1. Temporal convolution with residual\n        identity = x\n        x_temporal = self.temporal_conv(x)\n        x_temporal = self.dropout(x_temporal)\n        x = self.layer_norm1(identity + x_temporal)\n        \n        # 2. Spatial graph convolution with residual\n        identity = x\n        # Reshape for spatial processing: [batch * time, nodes, features]\n        x_spatial = x.permute(0, 2, 1, 3).reshape(batch * time, nodes, features)\n        x_spatial = self.spatial_conv(x_spatial, edge_index)\n        x_spatial = self.dropout(x_spatial)\n        # Reshape back: [batch, nodes, time, features]\n        x_spatial = x_spatial.reshape(batch, time, nodes, features).permute(0, 2, 1, 3)\n        x = self.layer_norm2(identity + x_spatial)\n        \n        # 3. Feed-forward network with residual\n        identity = x\n        x_ffn = self.ffn(x)\n        x = self.layer_norm3(identity + x_ffn)\n        \n        return x\n\n\nclass STGNNPredictor(nn.Module):\n    \"\"\"\n    Complete Spatio-Temporal GNN for Climate Prediction.\n    \n    Architecture:\n    1. Input embedding (8 channels → hidden_dim)\n    2. Positional encoding\n    3. Multiple STGNN blocks\n    4. Temporal projection (12 → 3 timesteps)\n    5. Output projection (hidden_dim → 1)\n    \"\"\"\n    \n    def __init__(self,\n                 input_channels: int = 8,\n                 hidden_dim: int = 64,\n                 num_blocks: int = 3,\n                 temporal_kernel: int = 3,\n                 spatial_size: Tuple[int, int] = (9, 19),\n                 input_length: int = 12,\n                 output_length: int = 3,\n                 dropout: float = 0.2):\n        super().__init__()\n        \n        self.input_channels = input_channels\n        self.hidden_dim = hidden_dim\n        self.num_blocks = num_blocks\n        self.spatial_size = spatial_size\n        self.num_nodes = spatial_size[0] * spatial_size[1]\n        self.input_length = input_length\n        self.output_length = output_length\n        \n        print(f\"🔧 Initializing STGNN Predictor:\")\n        print(f\"   Input: {input_length} timesteps × {input_channels} channels × {spatial_size[0]}×{spatial_size[1]}\")\n        print(f\"   Hidden: {hidden_dim}, Blocks: {num_blocks}\")\n        print(f\"   Output: {output_length} timesteps\")\n        \n        # Build graph structure\n        self.edge_index = build_grid_graph_8neighbor(spatial_size[0], spatial_size[1])\n        self.edge_index = add_self_loops(self.edge_index, self.num_nodes)\n        \n        # Positional encoding\n        self.pos_encoding = get_positional_encoding(spatial_size[0], spatial_size[1], hidden_dim)\n        \n        # Input embedding\n        self.input_embed = nn.Linear(input_channels, hidden_dim)\n        \n        # STGNN blocks\n        self.stgnn_blocks = nn.ModuleList([\n            STGNNBlock(hidden_dim, temporal_kernel, dropout)\n            for _ in range(num_blocks)\n        ])\n        \n        # Temporal projection: 12 timesteps → 3 timesteps\n        # self.temporal_proj = nn.Conv1d(input_length, output_length, kernel_size=1)\n        self.temporal_proj = nn.Linear(self.input_length, self.output_length)\n        \n        # Output projection\n        self.output_proj = nn.Sequential(\n            nn.Linear(hidden_dim, hidden_dim // 2),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim // 2, 1)\n        )\n        \n        # Non-negative activation for precipitation\n        self.output_activation = nn.Softplus(beta=10)\n        \n        num_params = sum(p.numel() for p in self.parameters())\n        print(f\"✅ STGNN initialized - Parameters: {num_params:,}\")\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Args:\n            x: [batch, seq_len, channels, height, width]\n        Returns:\n            predictions: [batch, output_length, 1, height, width]\n        \"\"\"\n        batch_size, seq_len, channels, height, width = x.shape\n        edge_index = self.edge_index.to(x.device)\n        \n        # Reshape to [batch, nodes, time, channels]\n        x = x.permute(0, 1, 3, 4, 2)  # [batch, time, height, width, channels]\n        x = x.reshape(batch_size, seq_len, self.num_nodes, channels)\n        x = x.permute(0, 2, 1, 3)  # [batch, nodes, time, channels]\n        \n        # Input embedding\n        x = self.input_embed(x)  # [batch, nodes, time, hidden_dim]\n        \n        # Add positional encoding\n        pos_enc = self.pos_encoding.to(x.device)  # [nodes, hidden_dim]\n        pos_enc = pos_enc.unsqueeze(0).unsqueeze(2)  # [1, nodes, 1, hidden_dim]\n        x = x + pos_enc\n        \n        # Process through STGNN blocks\n        for block in self.stgnn_blocks:\n            x = block(x, edge_index)\n        \n        # x shape: [batch, nodes, time, hidden_dim]\n        \n        # Temporal projection: 12 → 3 timesteps\n        # x_temp: [batch * nodes, time, hidden_dim]\n        x_temp = x.reshape(batch_size * self.num_nodes, seq_len, self.hidden_dim)\n        \n        # Permute to [batch*nodes, hidden_dim, time] so Linear acts on last dim=time\n        x_temp = x_temp.permute(0, 2, 1)  # [B*N, hidden_dim, seq_len]\n        \n        # Apply Linear to the time axis: Linear(seq_len -> output_length)\n        # The Linear acts on the last dimension (seq_len) and returns [B*N, hidden_dim, output_length]\n        x_temp = self.temporal_proj(x_temp)\n        \n        # Permute and reshape to [batch, nodes, output_length, hidden_dim]\n        x_temp = x_temp.permute(0, 2, 1).reshape(batch_size, self.num_nodes, self.output_length, self.hidden_dim)\n\n        \n        # Output projection\n        predictions = self.output_proj(x_temp)  # [batch, nodes, output_length, 1]\n        predictions = self.output_activation(predictions)\n        \n        # Reshape to [batch, output_length, 1, height, width]\n        predictions = predictions.squeeze(-1)  # [batch, nodes, output_length]\n        predictions = predictions.reshape(batch_size, height, width, self.output_length)\n        predictions = predictions.permute(0, 3, 1, 2).unsqueeze(2)  # [batch, output_length, 1, height, width]\n        \n        return predictions\n\n\nprint(\"✅ STGNN architecture defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T11:32:21.481289Z","iopub.execute_input":"2025-10-09T11:32:21.481500Z","iopub.status.idle":"2025-10-09T11:32:21.503870Z","shell.execute_reply.started":"2025-10-09T11:32:21.481485Z","shell.execute_reply":"2025-10-09T11:32:21.503347Z"}},"outputs":[{"name":"stdout","text":"✅ STGNN architecture defined\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## 🚂 Section 6: Training Function\n\n*Updated for STGNN model*","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# 🚂 SECTION 6: TRAINING FUNCTION FOR STGNN\n# ============================================================================\n\ndef train_single_institution_multi_scenario(institution: str) -> dict:\n    \"\"\"Train STGNN for single institution with multi-scenario data.\"\"\"\n    \n    print(f\"\\n{'='*80}\")\n    print(f\"🌐 Training STGNN: {institution}\")\n    print(f\"{'='*80}\")\n    \n    start_time = time.time()\n    \n    model_path = os.path.join(OUTPUT_DIR, \"checkpoints\", f\"{institution}_stgnn_multiscenario_best.pt\")\n    \n    if RESUME_IF_MODEL_EXISTS and os.path.exists(model_path):\n        print(f\"⭐ Model exists - skipping {institution}\")\n        return {'success': True, 'institution': institution, 'skipped': True}\n    \n    try:\n        # Data loader\n        print(\"📊 Step 1/7: Initializing data loader...\")\n        dl = MultiScenarioDataLoader(target_h=TARGET_SPATIAL_H, target_w=TARGET_SPATIAL_W)\n        \n        # Discover files\n        print(\"🔍 Step 2/7: Discovering files...\")\n        all_scenario_files = dl.discover_files_multi_scenario(institution)\n        \n        has_data = any(\n            bool(files['inputs']) or bool(files['outputs'])\n            for files in all_scenario_files.values()\n        )\n        \n        if not has_data:\n            print(f\"⚠️ No data for {institution}\")\n            return {'success': False, 'institution': institution, 'error': 'No data'}\n        \n        # Load scenarios\n        print(\"📊 Step 3/7: Loading data...\")\n        all_scenario_data = dl.load_all_scenarios(all_scenario_files)\n        \n        if not all_scenario_data:\n            print(f\"⚠️ Failed to load data\")\n            return {'success': False, 'institution': institution, 'error': 'Load failed'}\n        \n        # Create sequences\n        print(\"🔄 Step 4/7: Creating sequences...\")\n        data_splits, dataloaders = dl.create_multi_scenario_sequences(all_scenario_data)\n        \n        # Create STGNN model\n        print(\"🧠 Step 5/7: Creating STGNN model...\")\n        model = STGNNPredictor(\n            input_channels=NUM_INPUT_CHANNELS,\n            hidden_dim=HIDDEN_DIM,\n            num_blocks=STGNN_BLOCKS,\n            temporal_kernel=TEMPORAL_KERNEL_SIZE,\n            spatial_size=(TARGET_SPATIAL_H, TARGET_SPATIAL_W),\n            input_length=12,\n            output_length=3,\n            dropout=DROPOUT\n        ).to(device)\n        \n        optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.05)\n        criterion = nn.MSELoss()\n        \n        history = {\n            'train_loss': [],\n            'val_loss': [],\n            'scenario_losses': {}\n        }\n        best_val_loss = float('inf')\n        \n        print(f\"\\n🚂 Step 6/7: Training for {EPOCHS} epochs...\")\n        \n        epoch_pbar = tqdm(range(EPOCHS), desc=f\"🌐 {institution}\", position=0, leave=True)\n        \n        for ep in epoch_pbar:\n            # Training\n            model.train()\n            train_loss = 0.0\n            train_batches = 0\n            \n            for X, y, scenarios in dataloaders['train']:\n                try:\n                    X, y = X.to(device), y.to(device)\n                    optimizer.zero_grad()\n                    preds = model(X)\n                    \n                    if preds.shape != y.shape:\n                        if preds.ndim == 4 and y.ndim == 5:\n                            preds = preds.unsqueeze(2)\n                    \n                    loss = criterion(preds, y)\n                    loss.backward()\n                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n                    optimizer.step()\n                    \n                    train_loss += loss.item()\n                    train_batches += 1\n                    \n                    if train_batches % 10 == 0:\n                        torch.cuda.empty_cache()\n                except Exception as e:\n                    print(f\"\\n❌ Training error: {e}\")\n                    continue\n            \n            avg_train_loss = train_loss / max(1, train_batches)\n            history['train_loss'].append(avg_train_loss)\n            \n            # Validation\n            model.eval()\n            val_loss = 0.0\n            val_batches = 0\n            scenario_losses = {s: [] for s in SCENARIOS.keys()}\n            \n            with torch.no_grad():\n                for Xv, yv, scenarios_v in dataloaders['validation']:\n                    try:\n                        Xv, yv = Xv.to(device), yv.to(device)\n                        preds = model(Xv)\n                        \n                        if preds.shape != yv.shape:\n                            if preds.ndim == 4 and yv.ndim == 5:\n                                preds = preds.unsqueeze(2)\n                        \n                        batch_loss = criterion(preds, yv)\n                        val_loss += batch_loss.item()\n                        val_batches += 1\n                        \n                        # Track per-scenario\n                        for i, scenario_id in enumerate(scenarios_v.cpu().numpy()):\n                            scenario_name = [k for k, v in SCENARIOS.items() if v == scenario_id][0]\n                            scenario_losses[scenario_name].append(batch_loss.item())\n                    except Exception as e:\n                        print(f\"\\n❌ Validation error: {e}\")\n                        continue\n            \n            avg_val_loss = val_loss / max(1, val_batches)\n            history['val_loss'].append(avg_val_loss)\n            \n            avg_scenario_losses = {\n                s: np.mean(losses) if losses else 0.0\n                for s, losses in scenario_losses.items()\n            }\n            history['scenario_losses'][f'epoch_{ep+1}'] = avg_scenario_losses\n            \n            is_best = avg_val_loss < best_val_loss\n            if is_best:\n                best_val_loss = avg_val_loss\n                best_indicator = \"⭐ NEW BEST\"\n            else:\n                best_indicator = \"\"\n            \n            epoch_pbar.set_postfix({\n                'train': f'{avg_train_loss:.6f}',\n                'val': f'{avg_val_loss:.6f}',\n                'best': f'{best_val_loss:.6f}',\n                'status': best_indicator\n            })\n            \n            if ep % 3 == 0:\n                torch.cuda.empty_cache()\n                gc.collect()\n        \n        epoch_pbar.close()\n        \n        # Save model\n        print(\"💾 Step 7/7: Saving model...\")\n        torch.save({\n            'institution': institution,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'history': history,\n            'best_val_loss': best_val_loss,\n            'spatial_dims': [TARGET_SPATIAL_H, TARGET_SPATIAL_W],\n            'scenarios': list(SCENARIOS.keys()),\n            'timestamp': datetime.now().isoformat()\n        }, model_path)\n        \n        # Save results\n        summary = {\n            'institution': institution,\n            'training_time': time.time() - start_time,\n            'epochs_trained': len(history['train_loss']),\n            'best_val_loss': best_val_loss,\n            'spatial_dims': [TARGET_SPATIAL_H, TARGET_SPATIAL_W],\n            'scenarios': list(SCENARIOS.keys()),\n            'final_scenario_losses': history['scenario_losses'].get(f'epoch_{EPOCHS}', {}),\n            'timestamp': datetime.now().isoformat()\n        }\n        \n        results_path = os.path.join(OUTPUT_DIR, \"logs\", f\"{institution}_stgnn_phase4_results.json\")\n        with open(results_path, 'w') as f:\n            json.dump(summary, f, indent=2)\n        \n        return {'success': True, 'institution': institution, 'results': summary}\n    \n    except Exception as e:\n        print(f\"\\n❌ FATAL ERROR: {e}\")\n        import traceback\n        traceback.print_exc()\n        return {'success': False, 'institution': institution, 'error': str(e)}\n    \n    finally:\n        torch.cuda.empty_cache()\n        gc.collect()\n\n\nprint(\"✅ Training function defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T11:32:21.504817Z","iopub.execute_input":"2025-10-09T11:32:21.505568Z","iopub.status.idle":"2025-10-09T11:32:21.525940Z","shell.execute_reply.started":"2025-10-09T11:32:21.505542Z","shell.execute_reply":"2025-10-09T11:32:21.525200Z"}},"outputs":[{"name":"stdout","text":"✅ Training function defined\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## 🚀 Section 7: Main Training Loop\n\n*Same structure, updated for STGNN*","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# 🚀 SECTION 7: MAIN TRAINING EXECUTION\n# ============================================================================\n\nprint(\"=\"*80)\nprint(\"🌐 STGNN Phase 4 - Multi-Scenario Training\")\nprint(\"=\"*80)\nprint(f\"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\nsys.stdout.flush()\n\n# Determine institutions\nif SMOKE_TEST:\n    institutions = ALL_INSTITUTIONS[:2]\n    print(f\"⚠️ SMOKE TEST - Training only {len(institutions)} institutions\")\nelse:\n    institutions = ALL_INSTITUTIONS\n    print(f\"📋 Training all {len(institutions)} institutions\")\n\nprint(f\"   Model: Spatio-Temporal GNN\")\nprint(f\"   Scenarios: {list(SCENARIOS.keys())}\")\nprint(f\"   Spatial: {TARGET_SPATIAL_H}×{TARGET_SPATIAL_W}\")\nprint(f\"   STGNN Blocks: {STGNN_BLOCKS}\")\nprint(f\"   Batch size: {BATCH_SIZE}\")\nprint(f\"   Epochs: {EPOCHS}\")\nprint(f\"   Input channels: {NUM_INPUT_CHANNELS}\")\nsys.stdout.flush()\n\nif torch.cuda.is_available():\n    print(f\"\\n🎮 GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.1f} GB\")\n\nif SKIP_TRAINING:\n    print(\"SKIP_TRAINING=True - Loading existing results...\")\n    summary_path = os.path.join(OUTPUT_DIR, \"logs\", \"stgnn_phase4_training_summary.json\")\n    if os.path.exists(summary_path):\n        with open(summary_path, 'r') as f:\n            summary = json.load(f)\n        print(\"✅ Loaded existing results\")\n    else:\n        summary = {}\nelse:\n    print(\"\\n\" + \"=\"*80)\n    print(\"🚂 STARTING TRAINING\")\n    print(\"=\"*80)\n    sys.stdout.flush()\n    \n    t0 = time.time()\n    all_results = []\n    \n    main_pbar = tqdm(institutions, desc=\"🌐 Overall\", position=0)\n    \n    for inst_idx, institution in enumerate(main_pbar):\n        print(f\"\\n{'='*80}\")\n        print(f\"Institution {inst_idx+1}/{len(institutions)}: {institution}\")\n        print(f\"{'='*80}\")\n        sys.stdout.flush()\n        \n        try:\n            result = train_single_institution_multi_scenario(institution)\n            all_results.append(result)\n            \n            successful = sum(1 for r in all_results if r.get('success') and not r.get('skipped'))\n            skipped = sum(1 for r in all_results if r.get('skipped'))\n            failed = sum(1 for r in all_results if not r.get('success'))\n            \n            main_pbar.set_postfix({\n                'success': successful,\n                'skipped': skipped,\n                'failed': failed\n            })\n            \n            # Save progress\n            progress = {\n                'completed': len(all_results),\n                'total': len(institutions),\n                'results': all_results,\n                'timestamp': datetime.now().isoformat()\n            }\n            \n            progress_path = os.path.join(OUTPUT_DIR, \"logs\", \"stgnn_phase4_progress.json\")\n            with open(progress_path, 'w') as f:\n                json.dump(progress, f, indent=2)\n        \n        except Exception as e:\n            print(f\"\\n❌ CRITICAL ERROR: {e}\")\n            all_results.append({\n                'success': False,\n                'institution': institution,\n                'error': str(e)\n            })\n    \n    main_pbar.close()\n    elapsed = time.time() - t0\n    \n    # Summary\n    successful = [r for r in all_results if r.get('success') and not r.get('skipped')]\n    skipped = [r for r in all_results if r.get('skipped')]\n    failed = [r for r in all_results if not r.get('success')]\n    \n    summary = {\n        'model_type': 'STGNN',\n        'phase': 'phase4_multi_scenario',\n        'total_institutions': len(institutions),\n        'successful': len(successful),\n        'skipped': len(skipped),\n        'failed': len(failed),\n        'total_time_hours': elapsed / 3600,\n        'scenarios': list(SCENARIOS.keys()),\n        'results': all_results,\n        'timestamp': datetime.now().isoformat()\n    }\n    \n    summary_path = os.path.join(OUTPUT_DIR, \"logs\", \"stgnn_phase4_training_summary.json\")\n    with open(summary_path, 'w') as f:\n        json.dump(summary, f, indent=2)\n    \n    print(f\"\\n{'='*80}\")\n    print(\"✅ STGNN Phase 4 Training Complete!\")\n    print(f\"{'='*80}\")\n    print(f\"Total: {len(institutions)}\")\n    print(f\"  ✅ Successful: {len(successful)}\")\n    print(f\"  ⭐ Skipped: {len(skipped)}\")\n    print(f\"  ❌ Failed: {len(failed)}\")\n    print(f\"Total time: {elapsed/3600:.2f} hours\")\n    print(f\"{'='*80}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T11:32:21.527793Z","iopub.execute_input":"2025-10-09T11:32:21.527987Z","iopub.status.idle":"2025-10-09T11:50:49.300331Z","shell.execute_reply.started":"2025-10-09T11:32:21.527972Z","shell.execute_reply":"2025-10-09T11:50:49.299470Z"}},"outputs":[{"name":"stdout","text":"================================================================================\n🌐 STGNN Phase 4 - Multi-Scenario Training\n================================================================================\nStart time: 2025-10-09 11:32:21\n⚠️ SMOKE TEST - Training only 2 institutions\n   Model: Spatio-Temporal GNN\n   Scenarios: ['historical', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n   Spatial: 9×19\n   STGNN Blocks: 3\n   Batch size: 1\n   Epochs: 2\n   Input channels: 8\n\n🎮 GPU: Tesla P100-PCIE-16GB\n   Memory: 15.9 GB\n\n================================================================================\n🚂 STARTING TRAINING\n================================================================================\n","output_type":"stream"},{"name":"stderr","text":"🌐 Overall:   0%|          | 0/2 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\n================================================================================\nInstitution 1/2: AWI-CM-1-1-MR\n================================================================================\n\n================================================================================\n🌐 Training STGNN: AWI-CM-1-1-MR\n================================================================================\n📊 Step 1/7: Initializing data loader...\n📊 DataLoader initialized: 9×19\n🔍 Step 2/7: Discovering files...\n🔍 Discovering files for AWI-CM-1-1-MR...\n   📁 historical\n      ✓ BC_anthro_fires: 165 files\n      ✓ BC_no_fires: 165 files\n      ✓ CH4_anthro_fires: 165 files\n      ✓ CH4_no_fires: 165 files\n      ✓ CO2_sum: 165 files\n      ✓ SO2_anthro_fires: 165 files\n      ✓ SO2_no_fires: 165 files\n      ✓ pr: 165 files\n   📁 ssp126\n      ✓ BC_anthro_fires: 86 files\n      ✓ BC_no_fires: 86 files\n      ✓ CH4_anthro_fires: 86 files\n      ✓ CH4_no_fires: 86 files\n      ✓ CO2_sum: 86 files\n      ✓ SO2_anthro_fires: 86 files\n      ✓ SO2_no_fires: 86 files\n      ✓ pr: 86 files\n   📁 ssp245\n      ✓ BC_anthro_fires: 86 files\n      ✓ BC_no_fires: 86 files\n      ✓ CH4_anthro_fires: 86 files\n      ✓ CH4_no_fires: 86 files\n      ✓ CO2_sum: 86 files\n      ✓ SO2_anthro_fires: 86 files\n      ✓ SO2_no_fires: 86 files\n      ✓ pr: 86 files\n   📁 ssp370\n      ✓ BC_anthro_fires: 86 files\n      ✓ BC_no_fires: 86 files\n      ✓ CH4_anthro_fires: 86 files\n      ✓ CH4_no_fires: 86 files\n      ✓ CO2_sum: 86 files\n      ✓ SO2_anthro_fires: 86 files\n      ✓ SO2_no_fires: 86 files\n      ✓ pr: 86 files\n   📁 ssp585\n      ✓ BC_anthro_fires: 86 files\n      ✓ BC_no_fires: 86 files\n      ✓ CH4_anthro_fires: 86 files\n      ✓ CH4_no_fires: 86 files\n      ✓ CO2_sum: 86 files\n      ✓ SO2_anthro_fires: 86 files\n      ✓ SO2_no_fires: 86 files\n      ✓ pr: 86 files\n📊 Step 3/7: Loading data...\n📊 Loading scenarios...\n   📁 historical\n      ✓ BC_anthro_fires: (1980, 96, 144)\n      ✓ BC_no_fires: (1980, 96, 144)\n      ✓ CH4_anthro_fires: (1980, 96, 144)\n      ✓ CH4_no_fires: (1980, 96, 144)\n      ✓ CO2_sum: (1980, 96, 144)\n      ✓ SO2_anthro_fires: (1980, 96, 144)\n      ✓ SO2_no_fires: (1980, 96, 144)\n      ✓ pr: (1980, 96, 144)\n      🔽 Downsampling...\n         BC_anthro_fires: (1980, 96, 144) → (1980, 9, 19)\n         BC_no_fires: (1980, 96, 144) → (1980, 9, 19)\n         CH4_anthro_fires: (1980, 96, 144) → (1980, 9, 19)\n         CH4_no_fires: (1980, 96, 144) → (1980, 9, 19)\n         CO2_sum: (1980, 96, 144) → (1980, 9, 19)\n         SO2_anthro_fires: (1980, 96, 144) → (1980, 9, 19)\n         SO2_no_fires: (1980, 96, 144) → (1980, 9, 19)\n         pr: (1980, 96, 144) → (1980, 9, 19)\n   📁 ssp126\n      ✓ BC_anthro_fires: (1032, 96, 144)\n      ✓ BC_no_fires: (1032, 96, 144)\n      ✓ CH4_anthro_fires: (1032, 96, 144)\n      ✓ CH4_no_fires: (1032, 96, 144)\n      ✓ CO2_sum: (1032, 96, 144)\n      ✓ SO2_anthro_fires: (1032, 96, 144)\n      ✓ SO2_no_fires: (1032, 96, 144)\n      ✓ pr: (1032, 96, 144)\n      🔽 Downsampling...\n         BC_anthro_fires: (1032, 96, 144) → (1032, 9, 19)\n         BC_no_fires: (1032, 96, 144) → (1032, 9, 19)\n         CH4_anthro_fires: (1032, 96, 144) → (1032, 9, 19)\n         CH4_no_fires: (1032, 96, 144) → (1032, 9, 19)\n         CO2_sum: (1032, 96, 144) → (1032, 9, 19)\n         SO2_anthro_fires: (1032, 96, 144) → (1032, 9, 19)\n         SO2_no_fires: (1032, 96, 144) → (1032, 9, 19)\n         pr: (1032, 96, 144) → (1032, 9, 19)\n   📁 ssp245\n      ✓ BC_anthro_fires: (1032, 96, 144)\n      ✓ BC_no_fires: (1032, 96, 144)\n      ✓ CH4_anthro_fires: (1032, 96, 144)\n      ✓ CH4_no_fires: (1032, 96, 144)\n      ✓ CO2_sum: (1032, 96, 144)\n      ✓ SO2_anthro_fires: (1032, 96, 144)\n      ✓ SO2_no_fires: (1032, 96, 144)\n      ✓ pr: (1032, 96, 144)\n      🔽 Downsampling...\n         BC_anthro_fires: (1032, 96, 144) → (1032, 9, 19)\n         BC_no_fires: (1032, 96, 144) → (1032, 9, 19)\n         CH4_anthro_fires: (1032, 96, 144) → (1032, 9, 19)\n         CH4_no_fires: (1032, 96, 144) → (1032, 9, 19)\n         CO2_sum: (1032, 96, 144) → (1032, 9, 19)\n         SO2_anthro_fires: (1032, 96, 144) → (1032, 9, 19)\n         SO2_no_fires: (1032, 96, 144) → (1032, 9, 19)\n         pr: (1032, 96, 144) → (1032, 9, 19)\n   📁 ssp370\n      ✓ BC_anthro_fires: (1032, 96, 144)\n      ✓ BC_no_fires: (1032, 96, 144)\n      ✓ CH4_anthro_fires: (1032, 96, 144)\n      ✓ CH4_no_fires: (1032, 96, 144)\n      ✓ CO2_sum: (1032, 96, 144)\n      ✓ SO2_anthro_fires: (1032, 96, 144)\n      ✓ SO2_no_fires: (1032, 96, 144)\n      ✓ pr: (1032, 96, 144)\n      🔽 Downsampling...\n         BC_anthro_fires: (1032, 96, 144) → (1032, 9, 19)\n         BC_no_fires: (1032, 96, 144) → (1032, 9, 19)\n         CH4_anthro_fires: (1032, 96, 144) → (1032, 9, 19)\n         CH4_no_fires: (1032, 96, 144) → (1032, 9, 19)\n         CO2_sum: (1032, 96, 144) → (1032, 9, 19)\n         SO2_anthro_fires: (1032, 96, 144) → (1032, 9, 19)\n         SO2_no_fires: (1032, 96, 144) → (1032, 9, 19)\n         pr: (1032, 96, 144) → (1032, 9, 19)\n   📁 ssp585\n      ✓ BC_anthro_fires: (1032, 96, 144)\n      ✓ BC_no_fires: (1032, 96, 144)\n      ✓ CH4_anthro_fires: (1032, 96, 144)\n      ✓ CH4_no_fires: (1032, 96, 144)\n      ✓ CO2_sum: (1032, 96, 144)\n      ✓ SO2_anthro_fires: (1032, 96, 144)\n      ✓ SO2_no_fires: (1032, 96, 144)\n      ✓ pr: (1032, 96, 144)\n      🔽 Downsampling...\n         BC_anthro_fires: (1032, 96, 144) → (1032, 9, 19)\n         BC_no_fires: (1032, 96, 144) → (1032, 9, 19)\n         CH4_anthro_fires: (1032, 96, 144) → (1032, 9, 19)\n         CH4_no_fires: (1032, 96, 144) → (1032, 9, 19)\n         CO2_sum: (1032, 96, 144) → (1032, 9, 19)\n         SO2_anthro_fires: (1032, 96, 144) → (1032, 9, 19)\n         SO2_no_fires: (1032, 96, 144) → (1032, 9, 19)\n         pr: (1032, 96, 144) → (1032, 9, 19)\n   ✅ Loaded 5 scenarios\n🔄 Step 4/7: Creating sequences...\n🔄 Creating sequences...\n   📦 historical (id=0)\n      ✓ 1966 sequences\n   📦 ssp126 (id=1)\n      ✓ 1018 sequences\n   📦 ssp245 (id=2)\n      ✓ 1018 sequences\n   📦 ssp370 (id=3)\n      ✓ 1018 sequences\n   📦 ssp585 (id=4)\n      ✓ 1018 sequences\n   🧩 Total: X=(6038, 12, 8, 9, 19), Y=(6038, 3, 1, 9, 19)\n   📊 Stratified split...\n   📦 Train:4226 Val:905 Test:907\n🧠 Step 5/7: Creating STGNN model...\n🔧 Initializing STGNN Predictor:\n   Input: 12 timesteps × 8 channels × 9×19\n   Hidden: 64, Blocks: 3\n   Output: 3 timesteps\n📊 Graph: 9×19 = 171 nodes, 1204 edges\n   Avg degree: 7.04\n✅ STGNN initialized - Parameters: 103,528\n\n🚂 Step 6/7: Training for 2 epochs...\n","output_type":"stream"},{"name":"stderr","text":"🌐 AWI-CM-1-1-MR: 100%|██████████| 2/2 [01:53<00:00, 56.77s/it, train=0.005311, val=0.008635, best=0.008081, status=]           \n🌐 Overall:   0%|          | 0/2 [09:41<?, ?it/s, success=1, skipped=0, failed=0]","output_type":"stream"},{"name":"stdout","text":"💾 Step 7/7: Saving model...\n","output_type":"stream"},{"name":"stderr","text":"🌐 Overall:  50%|█████     | 1/2 [09:41<09:41, 581.77s/it, success=1, skipped=0, failed=0]","output_type":"stream"},{"name":"stdout","text":"\n================================================================================\nInstitution 2/2: BCC-CSM2-MR\n================================================================================\n\n================================================================================\n🌐 Training STGNN: BCC-CSM2-MR\n================================================================================\n📊 Step 1/7: Initializing data loader...\n📊 DataLoader initialized: 9×19\n🔍 Step 2/7: Discovering files...\n🔍 Discovering files for BCC-CSM2-MR...\n   📁 historical\n      ✓ BC_anthro_fires: 165 files\n      ✓ BC_no_fires: 165 files\n      ✓ CH4_anthro_fires: 165 files\n      ✓ CH4_no_fires: 165 files\n      ✓ CO2_sum: 165 files\n      ✓ SO2_anthro_fires: 165 files\n      ✓ SO2_no_fires: 165 files\n      ✓ pr: 165 files\n   📁 ssp126\n      ✓ BC_anthro_fires: 86 files\n      ✓ BC_no_fires: 86 files\n      ✓ CH4_anthro_fires: 86 files\n      ✓ CH4_no_fires: 86 files\n      ✓ CO2_sum: 86 files\n      ✓ SO2_anthro_fires: 86 files\n      ✓ SO2_no_fires: 86 files\n      ✓ pr: 86 files\n   📁 ssp245\n      ✓ BC_anthro_fires: 86 files\n      ✓ BC_no_fires: 86 files\n      ✓ CH4_anthro_fires: 86 files\n      ✓ CH4_no_fires: 86 files\n      ✓ CO2_sum: 86 files\n      ✓ SO2_anthro_fires: 86 files\n      ✓ SO2_no_fires: 86 files\n      ✓ pr: 86 files\n   📁 ssp370\n      ✓ BC_anthro_fires: 86 files\n      ✓ BC_no_fires: 86 files\n      ✓ CH4_anthro_fires: 86 files\n      ✓ CH4_no_fires: 86 files\n      ✓ CO2_sum: 86 files\n      ✓ SO2_anthro_fires: 86 files\n      ✓ SO2_no_fires: 86 files\n      ✓ pr: 86 files\n   📁 ssp585\n      ✓ BC_anthro_fires: 86 files\n      ✓ BC_no_fires: 86 files\n      ✓ CH4_anthro_fires: 86 files\n      ✓ CH4_no_fires: 86 files\n      ✓ CO2_sum: 86 files\n      ✓ SO2_anthro_fires: 86 files\n      ✓ SO2_no_fires: 86 files\n      ✓ pr: 86 files\n📊 Step 3/7: Loading data...\n📊 Loading scenarios...\n   📁 historical\n      ✓ BC_anthro_fires: (1980, 96, 144)\n      ✓ BC_no_fires: (1980, 96, 144)\n      ✓ CH4_anthro_fires: (1980, 96, 144)\n      ✓ CH4_no_fires: (1980, 96, 144)\n      ✓ CO2_sum: (1980, 96, 144)\n      ✓ SO2_anthro_fires: (1980, 96, 144)\n      ✓ SO2_no_fires: (1980, 96, 144)\n      ✓ pr: (1980, 96, 144)\n      🔽 Downsampling...\n         BC_anthro_fires: (1980, 96, 144) → (1980, 9, 19)\n         BC_no_fires: (1980, 96, 144) → (1980, 9, 19)\n         CH4_anthro_fires: (1980, 96, 144) → (1980, 9, 19)\n         CH4_no_fires: (1980, 96, 144) → (1980, 9, 19)\n         CO2_sum: (1980, 96, 144) → (1980, 9, 19)\n         SO2_anthro_fires: (1980, 96, 144) → (1980, 9, 19)\n         SO2_no_fires: (1980, 96, 144) → (1980, 9, 19)\n         pr: (1980, 96, 144) → (1980, 9, 19)\n   📁 ssp126\n      ✓ BC_anthro_fires: (1032, 96, 144)\n      ✓ BC_no_fires: (1032, 96, 144)\n      ✓ CH4_anthro_fires: (1032, 96, 144)\n      ✓ CH4_no_fires: (1032, 96, 144)\n      ✓ CO2_sum: (1032, 96, 144)\n      ✓ SO2_anthro_fires: (1032, 96, 144)\n      ✓ SO2_no_fires: (1032, 96, 144)\n      ✓ pr: (1032, 96, 144)\n      🔽 Downsampling...\n         BC_anthro_fires: (1032, 96, 144) → (1032, 9, 19)\n         BC_no_fires: (1032, 96, 144) → (1032, 9, 19)\n         CH4_anthro_fires: (1032, 96, 144) → (1032, 9, 19)\n         CH4_no_fires: (1032, 96, 144) → (1032, 9, 19)\n         CO2_sum: (1032, 96, 144) → (1032, 9, 19)\n         SO2_anthro_fires: (1032, 96, 144) → (1032, 9, 19)\n         SO2_no_fires: (1032, 96, 144) → (1032, 9, 19)\n         pr: (1032, 96, 144) → (1032, 9, 19)\n   📁 ssp245\n      ✓ BC_anthro_fires: (1032, 96, 144)\n      ✓ BC_no_fires: (1032, 96, 144)\n      ✓ CH4_anthro_fires: (1032, 96, 144)\n      ✓ CH4_no_fires: (1032, 96, 144)\n      ✓ CO2_sum: (1032, 96, 144)\n      ✓ SO2_anthro_fires: (1032, 96, 144)\n      ✓ SO2_no_fires: (1032, 96, 144)\n      ✓ pr: (1032, 96, 144)\n      🔽 Downsampling...\n         BC_anthro_fires: (1032, 96, 144) → (1032, 9, 19)\n         BC_no_fires: (1032, 96, 144) → (1032, 9, 19)\n         CH4_anthro_fires: (1032, 96, 144) → (1032, 9, 19)\n         CH4_no_fires: (1032, 96, 144) → (1032, 9, 19)\n         CO2_sum: (1032, 96, 144) → (1032, 9, 19)\n         SO2_anthro_fires: (1032, 96, 144) → (1032, 9, 19)\n         SO2_no_fires: (1032, 96, 144) → (1032, 9, 19)\n         pr: (1032, 96, 144) → (1032, 9, 19)\n   📁 ssp370\n      ✓ BC_anthro_fires: (1032, 96, 144)\n      ✓ BC_no_fires: (1032, 96, 144)\n      ✓ CH4_anthro_fires: (1032, 96, 144)\n      ✓ CH4_no_fires: (1032, 96, 144)\n      ✓ CO2_sum: (1032, 96, 144)\n      ✓ SO2_anthro_fires: (1032, 96, 144)\n      ✓ SO2_no_fires: (1032, 96, 144)\n      ✓ pr: (1032, 96, 144)\n      🔽 Downsampling...\n         BC_anthro_fires: (1032, 96, 144) → (1032, 9, 19)\n         BC_no_fires: (1032, 96, 144) → (1032, 9, 19)\n         CH4_anthro_fires: (1032, 96, 144) → (1032, 9, 19)\n         CH4_no_fires: (1032, 96, 144) → (1032, 9, 19)\n         CO2_sum: (1032, 96, 144) → (1032, 9, 19)\n         SO2_anthro_fires: (1032, 96, 144) → (1032, 9, 19)\n         SO2_no_fires: (1032, 96, 144) → (1032, 9, 19)\n         pr: (1032, 96, 144) → (1032, 9, 19)\n   📁 ssp585\n      ✓ BC_anthro_fires: (1032, 96, 144)\n      ✓ CH4_anthro_fires: (1032, 96, 144)\n      ✓ CH4_no_fires: (1032, 96, 144)\n      ✓ CO2_sum: (1032, 96, 144)\n      ✓ SO2_anthro_fires: (1032, 96, 144)\n      ✓ SO2_no_fires: (1032, 96, 144)\n      ✓ pr: (1032, 96, 144)\n      🔽 Downsampling...\n         BC_anthro_fires: (1032, 96, 144) → (1032, 9, 19)\n         BC_no_fires: (1032, 96, 144) → (1032, 9, 19)\n         CH4_anthro_fires: (1032, 96, 144) → (1032, 9, 19)\n         CH4_no_fires: (1032, 96, 144) → (1032, 9, 19)\n         CO2_sum: (1032, 96, 144) → (1032, 9, 19)\n         SO2_anthro_fires: (1032, 96, 144) → (1032, 9, 19)\n         SO2_no_fires: (1032, 96, 144) → (1032, 9, 19)\n         pr: (1032, 96, 144) → (1032, 9, 19)\n   ✅ Loaded 5 scenarios\n🔄 Step 4/7: Creating sequences...\n🔄 Creating sequences...\n   📦 historical (id=0)\n      ✓ 1966 sequences\n   📦 ssp126 (id=1)\n      ✓ 1018 sequences\n   📦 ssp245 (id=2)\n      ✓ 1018 sequences\n   📦 ssp370 (id=3)\n      ✓ 1018 sequences\n   📦 ssp585 (id=4)\n      ✓ 1018 sequences\n   🧩 Total: X=(6038, 12, 8, 9, 19), Y=(6038, 3, 1, 9, 19)\n   📊 Stratified split...\n   📦 Train:4226 Val:905 Test:907\n🧠 Step 5/7: Creating STGNN model...\n🔧 Initializing STGNN Predictor:\n   Input: 12 timesteps × 8 channels × 9×19\n   Hidden: 64, Blocks: 3\n   Output: 3 timesteps\n📊 Graph: 9×19 = 171 nodes, 1204 edges\n   Avg degree: 7.04\n✅ STGNN initialized - Parameters: 103,528\n\n🚂 Step 6/7: Training for 2 epochs...\n","output_type":"stream"},{"name":"stderr","text":"🌐 BCC-CSM2-MR: 100%|██████████| 2/2 [01:48<00:00, 54.38s/it, train=0.002217, val=0.003915, best=0.003837, status=]           \n","output_type":"stream"},{"name":"stdout","text":"💾 Step 7/7: Saving model...\n","output_type":"stream"},{"name":"stderr","text":"🌐 Overall: 100%|██████████| 2/2 [18:27<00:00, 553.87s/it, success=2, skipped=0, failed=0]","output_type":"stream"},{"name":"stdout","text":"\n================================================================================\n✅ STGNN Phase 4 Training Complete!\n================================================================================\nTotal: 2\n  ✅ Successful: 2\n  ⭐ Skipped: 0\n  ❌ Failed: 0\nTotal time: 0.31 hours\n================================================================================\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## 📊 Section 8: Results Analysis","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# 📊 SECTION 8: RESULTS ANALYSIS\n# ============================================================================\n\nif summary:\n    print(\"\\n\" + \"=\"*80)\n    print(\"📊 STGNN PHASE 4 RESULTS SUMMARY\")\n    print(\"=\"*80)\n    print(f\"Model Type: {summary.get('model_type', 'STGNN')}\")\n    print(f\"Total institutions: {summary.get('total_institutions', 0)}\")\n    print(f\"  ✅ Successful: {summary.get('successful', 0)}\")\n    print(f\"  ⭐ Skipped: {summary.get('skipped', 0)}\")\n    print(f\"  ❌ Failed: {summary.get('failed', 0)}\")\n    print(f\"Total time: {summary.get('total_time_hours', 0):.2f}h\")\n    print(f\"Scenarios: {summary.get('scenarios', [])}\")\n    \n    # Scenario performance\n    print(f\"\\n🌍 Scenario Performance Across All Institutions:\")\n    print(\"=\"*80)\n    \n    scenario_perf = {s: [] for s in SCENARIOS.keys()}\n    \n    for result in summary.get('results', []):\n        if result.get('success') and not result.get('skipped'):\n            inst_results = result.get('results', {})\n            final_losses = inst_results.get('final_scenario_losses', {})\n            \n            for scenario, loss in final_losses.items():\n                if scenario in scenario_perf:\n                    scenario_perf[scenario].append(loss)\n    \n    for scenario, losses in scenario_perf.items():\n        if losses:\n            avg = np.mean(losses)\n            std = np.std(losses)\n            min_loss = np.min(losses)\n            max_loss = np.max(losses)\n            print(f\"   {scenario.upper():12s}: Avg={avg:.6f}±{std:.6f} | Min={min_loss:.6f} | Max={max_loss:.6f}\")\n        else:\n            print(f\"   {scenario.upper():12s}: No data\")\n    \n    print(\"=\"*80)\n    \n    # Visualization\n    if scenario_perf and any(scenario_perf.values()):\n        fig, ax = plt.subplots(figsize=(12, 6))\n        \n        scenarios_with_data = [s for s, losses in scenario_perf.items() if losses]\n        avg_losses = [np.mean(scenario_perf[s]) for s in scenarios_with_data]\n        std_losses = [np.std(scenario_perf[s]) for s in scenarios_with_data]\n        \n        x = np.arange(len(scenarios_with_data))\n        ax.bar(x, avg_losses, yerr=std_losses, capsize=5, alpha=0.7, color='teal')\n        ax.set_xlabel('Scenario', fontsize=12)\n        ax.set_ylabel('Average Loss', fontsize=12)\n        ax.set_title('STGNN Performance Across Climate Scenarios', fontsize=14, fontweight='bold')\n        ax.set_xticks(x)\n        ax.set_xticklabels([s.upper() for s in scenarios_with_data], rotation=45)\n        ax.grid(True, alpha=0.3)\n        \n        plt.tight_layout()\n        plt.savefig(os.path.join(OUTPUT_DIR, \"plots\", \"stgnn_scenario_performance.png\"), \n                   dpi=300, bbox_inches='tight')\n        plt.show()\n        \n        print(f\"\\n📊 Plot saved to: {OUTPUT_DIR}/plots/stgnn_scenario_performance.png\")\n\nprint(f\"\\n✅ Results saved to: {OUTPUT_DIR}\")\nprint(\"=\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T11:50:49.301163Z","iopub.execute_input":"2025-10-09T11:50:49.301706Z","iopub.status.idle":"2025-10-09T11:50:50.042297Z","shell.execute_reply.started":"2025-10-09T11:50:49.301688Z","shell.execute_reply":"2025-10-09T11:50:50.041399Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\n📊 STGNN PHASE 4 RESULTS SUMMARY\n================================================================================\nModel Type: STGNN\nTotal institutions: 2\n  ✅ Successful: 2\n  ⭐ Skipped: 0\n  ❌ Failed: 0\nTotal time: 0.31h\nScenarios: ['historical', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n\n🌍 Scenario Performance Across All Institutions:\n================================================================================\n   HISTORICAL  : Avg=0.005502±0.001938 | Min=0.003564 | Max=0.007441\n   SSP126      : Avg=0.005725±0.001930 | Min=0.003795 | Max=0.007655\n   SSP245      : Avg=0.006083±0.002559 | Min=0.003524 | Max=0.008642\n   SSP370      : Avg=0.007052±0.002387 | Min=0.004665 | Max=0.009439\n   SSP585      : Avg=0.007740±0.003385 | Min=0.004355 | Max=0.011125\n================================================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"\n📊 Plot saved to: stgnn_phase4_multiscenario_results/plots/stgnn_scenario_performance.png\n\n✅ Results saved to: stgnn_phase4_multiscenario_results\n================================================================================\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"---\n\n## 🎉 Complete!\n\n### 🌟 What's Different: STGNN vs GNN-GRU\n\n| Component | **Previous (GNN-GRU)** | **Now (STGNN)** |\n|-----------|----------------------|----------------|\n| **Architecture** | Separate spatial (GNN) + temporal (GRU) | Unified spatio-temporal blocks |\n| **Temporal** | GRU (sequential) | Temporal convolution (parallel) |\n| **Processing** | Sequential over time | Processes all timesteps together |\n| **Efficiency** | Moderate (GRU overhead) | Higher (parallel processing) |\n| **Parameters** | ~1-1.5M | ~800K-1.2M |\n| **Training Speed** | Slower (sequential) | Faster (parallel) |\n| **Climate Data** | Good | Better (captures ST patterns) |\n\n### 🔬 STGNN Architecture:\n```\nInput (12×8×9×19)\n    ↓\n[Graph: 8-neighbor connectivity]\n    ↓\n[Input Embed: 8 → 64]\n[+ Positional Encoding]\n    ↓\n╔═══════════════════════════════════╗\n║   STGNN Block × 3                 ║\n║   ┌─────────────────────────┐    ║\n║   │ Temporal Conv (1D)      │    ║\n║   │ ↓                       │    ║\n║   │ Graph Conv (Spatial)    │    ║\n║   │ ↓                       │    ║\n║   │ Feed-Forward Network    │    ║\n║   │ ↓                       │    ║\n║   │ Layer Norm + Residual   │    ║\n║   └─────────────────────────┘    ║\n╚═══════════════════════════════════╝\n    ↓\n[Temporal Projection: 12 → 3]\n    ↓\n[Output Projection: 64 → 1]\n[+ Softplus]\n    ↓\nOutput (3×1×9×19)\n```\n\n### 🎯 Key Advantages of STGNN:\n\n#### **1. Unified Processing**\n- Processes spatial and temporal together\n- No separation between spatial and temporal\n- More natural for climate data\n\n#### **2. Parallel Temporal Processing**\n```python\n# GNN-GRU (Sequential)\nfor t in timesteps:\n    hidden = gru_cell(x[t], hidden)  # One at a time\n\n# STGNN (Parallel)\nx_all_time = temporal_conv(x)  # All at once!\n```\n\n#### **3. Causal Temporal Convolutions**\n- Only looks at past (causal padding)\n- Respects temporal ordering\n- Prevents information leakage\n\n#### **4. Better for Climate**\n- Climate has strong spatio-temporal correlations\n- STGNN captures these naturally\n- No artificial separation\n\n### 📊 Expected Performance:\n\n| Metric | STGNN Expected | Previous GNN-GRU |\n|--------|---------------|------------------|\n| **Training Speed** | **~30-40 min/epoch** | ~45-60 min/epoch |\n| **Memory** | **~3-4 GB** | ~4-5 GB |\n| **Parameters** | **~800K-1.2M** | ~1-1.5M |\n| **MAE** | **0.0003-0.0008** | 0.0004-0.0010 |\n| **R²** | **0.7-0.92** | 0.65-0.88 |\n\n### 🔧 Technical Details:\n\n#### **Temporal Convolution**\n```python\n# 1D convolution over time\n# Kernel size 3 = looks at [t-2, t-1, t]\n# Causal padding = no future information\n```\n\n#### **Spatio-Temporal Block**\n```python\n1. Temporal Conv → captures time patterns\n2. Graph Conv → captures spatial patterns  \n3. FFN → non-linear transformations\n4. Layer Norm + Residual → stable training\n```\n\n#### **Temporal Projection**\n```python\n# Projects 12 input timesteps → 3 output timesteps\n# Learnable Conv1d(12, 3)\n# More flexible than taking last 3\n```\n\n### 📁 Output Files:\n- **Models**: `stgnn_phase4_multiscenario_results/checkpoints/{inst}_stgnn_multiscenario_best.pt`\n- **Logs**: `stgnn_phase4_multiscenario_results/logs/{inst}_stgnn_phase4_results.json`\n- **Summary**: `stgnn_phase4_multiscenario_results/logs/stgnn_phase4_training_summary.json`\n- **Plots**: `stgnn_phase4_multiscenario_results/plots/stgnn_scenario_performance.png`\n\n### 🚀 Ready to Compare!\n\nNow you have:\n1. ✅ ConvLSTM (CNN + LSTM)\n2. ✅ ClimAx (Vision Transformer)\n3. ✅ **STGNN** (Unified spatio-temporal graph)\n\n**Perfect for comprehensive comparison!**","metadata":{}}]}